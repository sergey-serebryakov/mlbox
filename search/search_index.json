{"config":{"indexing":"full","lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"MLCube \u00b6 Interested in getting started with MLCube? Follow the Getting Started instructions, or watch the video below. MLCube is a project that reduces friction for machine learning by ensuring that models are easily portable and reproducible, e.g., between different stacks such as different clouds, between cloud and on-prem, etc. Installing MLCube \u00b6 Install from PyPI: pip install mlcube To uninstall: pip uninstall mlcube Usage Examples \u00b6 Check out the examples for detailed examples. License \u00b6 MLCube is licensed under the Apache License 2.0. See LICENSE for more information. Support \u00b6 Create a GitHub issue","title":"Home"},{"location":"#mlcube","text":"Interested in getting started with MLCube? Follow the Getting Started instructions, or watch the video below. MLCube is a project that reduces friction for machine learning by ensuring that models are easily portable and reproducible, e.g., between different stacks such as different clouds, between cloud and on-prem, etc.","title":"MLCube"},{"location":"#installing-mlcube","text":"Install from PyPI: pip install mlcube To uninstall: pip uninstall mlcube","title":"Installing MLCube"},{"location":"#usage-examples","text":"Check out the examples for detailed examples.","title":"Usage Examples"},{"location":"#license","text":"MLCube is licensed under the Apache License 2.0. See LICENSE for more information.","title":"License"},{"location":"#support","text":"Create a GitHub issue","title":"Support"},{"location":"getting-started/","text":"Installation \u00b6 Here is the step-by-step guide to install MLCube library and run simple MLCube cubes. Create a python environment \u00b6 # Option 1: use python virtual environment `virtualenv`. virtualenv -p python3.6 ./env_mlcube && source ./env_mlcube/bin/activate # Option 2: use conda. conda create -n mlcube python=3.6 && conda activate mlcube Install MLCube Runners \u00b6 # Install MLCube Docker runner. pip install mlcube-docker # Optionally, install other runners. # pip install mlcube-gcp # pip install mlcube-k8s # pip install mlcube-kubeflow # pip install mlcube-singularity # pip install mlcube-ssh # Check that the docker runner has been installed. mlcube config --get runners # Show MLCube system settings. mlcube config --list # This system settings file (~/mlcube.yaml) configures local MLCube runners. Documentation # for MLCube runners describes each of these parameters in details. A typical first step for # enterprise environments that are usually behind a firewall is to configure proxy servers. # platforms: # docker: # env_args: # http_proxy: http://ADDRESS:PORT # https_proxy: https://ADDRESS:PORT # build_args: # http_proxy: http://ADDRESS:PORT # https_proxy: https://ADDRESS:PORT Explore with examples \u00b6 A great way to learn about MLCube is try out the example MLCube cubes located here . git clone https://github.com/mlcommons/mlcube_examples.git && cd ./mlcube_examples mlcube describe --mlcube ./mnist","title":"Installation"},{"location":"getting-started/#installation","text":"Here is the step-by-step guide to install MLCube library and run simple MLCube cubes.","title":"Installation"},{"location":"getting-started/#create-a-python-environment","text":"# Option 1: use python virtual environment `virtualenv`. virtualenv -p python3.6 ./env_mlcube && source ./env_mlcube/bin/activate # Option 2: use conda. conda create -n mlcube python=3.6 && conda activate mlcube","title":"Create a python environment"},{"location":"getting-started/#install-mlcube-runners","text":"# Install MLCube Docker runner. pip install mlcube-docker # Optionally, install other runners. # pip install mlcube-gcp # pip install mlcube-k8s # pip install mlcube-kubeflow # pip install mlcube-singularity # pip install mlcube-ssh # Check that the docker runner has been installed. mlcube config --get runners # Show MLCube system settings. mlcube config --list # This system settings file (~/mlcube.yaml) configures local MLCube runners. Documentation # for MLCube runners describes each of these parameters in details. A typical first step for # enterprise environments that are usually behind a firewall is to configure proxy servers. # platforms: # docker: # env_args: # http_proxy: http://ADDRESS:PORT # https_proxy: https://ADDRESS:PORT # build_args: # http_proxy: http://ADDRESS:PORT # https_proxy: https://ADDRESS:PORT","title":"Install MLCube Runners"},{"location":"getting-started/#explore-with-examples","text":"A great way to learn about MLCube is try out the example MLCube cubes located here . git clone https://github.com/mlcommons/mlcube_examples.git && cd ./mlcube_examples mlcube describe --mlcube ./mnist","title":"Explore with examples"},{"location":"getting-started/cli/","text":"Command Line Interface \u00b6 mlcube \u00b6 MLCube \ud83d\udce6 is a tool for packaging, distributing and running Machine Learning (ML) projects and models. GitHub: https://github.com/mlcommons/mlcube Documentation: https://mlcommons.github.io/mlcube/ Example MLCubes: https://github.com/mlcommons/mlcube_examples Usage: mlcube [OPTIONS] COMMAND [ARGS]... Options: Name Type Description Default --log-level , --log_level choice ( critical | error | warning | info | debug ) Logging level is a lower-case string value for Python's logging library (see Logging Levels for more details). Only messages with this logging level or higher are logged. warning --help , -h boolean Show help message and exit. False mlcube config \u00b6 Work with MLCube system settings similar to git config . Manage MLCube system settings (these settings define global configuration common for all MLCube runners and platforms). When this command runs without arguments, a path to system settings file is printed out. This is useful to automate certain operations with system settings. Alternatively, it may be easier to manipulate system settings file directly (it is a yaml file). Usage: mlcube config [OPTIONS] Options: Name Type Description Default --list boolean Print out the content of system settings file. False --get text Return value of the key (use OmegaConf notation, e.g. mlcube config --get runners.docker ). None --create_platform , --create-platform tuple Create a new platform instance for this runner. Default runner parameters are used to initialize this new platform. None --remove_platform , --remove-platform text Remove this platform. If this is one of the default platforms (e.g., docker ), it will be recreated (with default values) next time mlcube runs. None --rename_platform , --rename-platform tuple Rename existing platform. If default platform is to be renamed (e.g., docker ), it will be recreated (with default values) next time mlcube runs. None --copy_platform , --copy-platform tuple Copy existing platform. This can be useful for creating new platforms off existing platforms, for instance,creating a new SSH runner configuration that runs MLCubes on a new remote server. None --rename_runner , --rename-runner tuple Rename existing MLCube runner. If platforms exist that reference this runner, users must explicitly provide --update-platforms flag to confirm they want to update platforms' description too. None --remove_runner , --remove-runner text Remove existing runner. If platforms exist that reference this runner, users must explicitly provide --remove-platforms flag to confirm they want to remove platforms too. None --help , -h boolean Show help message and exit. False mlcube configure \u00b6 Configure MLCube. Some MLCube projects need to be configured first. For instance, docker-based MLCubes distributed via GitHub with source code most likely will provide a Dockerfile to build a docker image. In this case, the process of building a docker image before MLCube runner can run it, is called a configuration phase. In general, users do not need to run this command manually - MLCube runners should be able to figure out when they need to run it, and will run it as part of mlcube run command. Usage: mlcube configure [OPTIONS] Options: Name Type Description Default --mlcube text Path to an MLCube project. It can be a directory path , or a path to an MLCube configuration file . When it is a directory path, MLCube runtime assumes this directory is the MLCube root directory containing mlcube.yaml file. When it is a file path, this file is assumed to be the MLCube configuration file ( mlcube.yaml ), and a parent directory of this file is considered to be the MLCube root directory. Default value is current directory. None --platform text Platform name to run MLCube on (a platform is a configured instance of an MLCube runner). Multiple platforms are supported, including docker ( Docker and Podman ), singularity ( Singularity ). Other runners are in experimental stage: gcp ( Google Cloud Platform ), k8s ( Kubernetes ), kubeflow ( KubeFlow ), ssh ( SSH runner ). Default is docker . Platforms are defined and configured in MLCube system settings file . docker -P , -p text MLCube configuration parameter is a key-value pair. Must start with -P or '-p'. The dot (.) is used to refer to nested parameters, for instance, -Pdocker.build_strategy=always . These parameters have the highest priority and override any other parameters in system settings and MLCube configuration . None --help , -h boolean Show help message and exit. False mlcube create \u00b6 Create a new Python project from the MLCube cookiecutter template. MLCube uses the cookiecutter library with the mlcube_cookiecutter template. The library is not installed automatically: install it with pip install cookiecutter . Usage: mlcube create [OPTIONS] Options: Name Type Description Default --help , -h boolean Show help message and exit. False mlcube describe \u00b6 Describe this MLCube. Usage: mlcube describe [OPTIONS] Options: Name Type Description Default --mlcube text Path to an MLCube project. It can be a directory path , or a path to an MLCube configuration file . When it is a directory path, MLCube runtime assumes this directory is the MLCube root directory containing mlcube.yaml file. When it is a file path, this file is assumed to be the MLCube configuration file ( mlcube.yaml ), and a parent directory of this file is considered to be the MLCube root directory. Default value is current directory. None --help , -h boolean Show help message and exit. False mlcube run \u00b6 Run MLCube task(s). Usage: mlcube run [OPTIONS] Options: Name Type Description Default --mlcube text Path to an MLCube project. It can be a directory path , or a path to an MLCube configuration file . When it is a directory path, MLCube runtime assumes this directory is the MLCube root directory containing mlcube.yaml file. When it is a file path, this file is assumed to be the MLCube configuration file ( mlcube.yaml ), and a parent directory of this file is considered to be the MLCube root directory. Default value is current directory. None --platform text Platform name to run MLCube on (a platform is a configured instance of an MLCube runner). Multiple platforms are supported, including docker ( Docker and Podman ), singularity ( Singularity ). Other runners are in experimental stage: gcp ( Google Cloud Platform ), k8s ( Kubernetes ), kubeflow ( KubeFlow ), ssh ( SSH runner ). Default is docker . Platforms are defined and configured in MLCube system settings file . docker --task text MLCube task name(s) to run, default is main . This parameter can take a list of values, in which case task names are separated with comma (,). None --workspace text Location of a workspace to store input and output artifacts of MLCube tasks . If not specified (None), ${MLCUBE_ROOT}/workspace/ is used. None -P , -p text MLCube configuration parameter is a key-value pair. Must start with -P or '-p'. The dot (.) is used to refer to nested parameters, for instance, -Pdocker.build_strategy=always . These parameters have the highest priority and override any other parameters in system settings and MLCube configuration . None --help , -h boolean Show help message and exit. False mlcube show_config \u00b6 Show effective MLCube configuration. Effective MLCube configuration is the one used by one of MLCube runners to run this MLCube. This configuration is built by merging (1) default runner configuration retrieved from system settings, (2) MLCube project configuration and (3) configuration parameters passed by a user on a command line (CONFIG_PARAM). Usage: mlcube show_config [OPTIONS] Options: Name Type Description Default --mlcube text Path to an MLCube project. It can be a directory path , or a path to an MLCube configuration file . When it is a directory path, MLCube runtime assumes this directory is the MLCube root directory containing mlcube.yaml file. When it is a file path, this file is assumed to be the MLCube configuration file ( mlcube.yaml ), and a parent directory of this file is considered to be the MLCube root directory. Default value is current directory. None --platform text Platform name to run MLCube on (a platform is a configured instance of an MLCube runner). Multiple platforms are supported, including docker ( Docker and Podman ), singularity ( Singularity ). Other runners are in experimental stage: gcp ( Google Cloud Platform ), k8s ( Kubernetes ), kubeflow ( KubeFlow ), ssh ( SSH runner ). Default is docker . Platforms are defined and configured in MLCube system settings file . docker --workspace text Location of a workspace to store input and output artifacts of MLCube tasks . If not specified (None), ${MLCUBE_ROOT}/workspace/ is used. None --resolve boolean Resolve MLCube parameters . The mlcube uses OmegaConf library to manage its configuration, including configuration files , system settings files and configuration parameters provided by users on command lines. OmegaConf supports variable interpolation (when one variables depend on other variables, e.g., {'docker.image': 'mlcommons/{name}:${version}'} ). When this flag is set to true, the mlcube computes actual values of all variables. False -P , -p text MLCube configuration parameter is a key-value pair. Must start with -P or '-p'. The dot (.) is used to refer to nested parameters, for instance, -Pdocker.build_strategy=always . These parameters have the highest priority and override any other parameters in system settings and MLCube configuration . None --help , -h boolean Show help message and exit. False","title":"Command Line Interface"},{"location":"getting-started/cli/#command-line-interface","text":"","title":"Command Line Interface"},{"location":"getting-started/cli/#mlcube","text":"MLCube \ud83d\udce6 is a tool for packaging, distributing and running Machine Learning (ML) projects and models. GitHub: https://github.com/mlcommons/mlcube Documentation: https://mlcommons.github.io/mlcube/ Example MLCubes: https://github.com/mlcommons/mlcube_examples Usage: mlcube [OPTIONS] COMMAND [ARGS]... Options: Name Type Description Default --log-level , --log_level choice ( critical | error | warning | info | debug ) Logging level is a lower-case string value for Python's logging library (see Logging Levels for more details). Only messages with this logging level or higher are logged. warning --help , -h boolean Show help message and exit. False","title":"mlcube"},{"location":"getting-started/cli/#mlcube-config","text":"Work with MLCube system settings similar to git config . Manage MLCube system settings (these settings define global configuration common for all MLCube runners and platforms). When this command runs without arguments, a path to system settings file is printed out. This is useful to automate certain operations with system settings. Alternatively, it may be easier to manipulate system settings file directly (it is a yaml file). Usage: mlcube config [OPTIONS] Options: Name Type Description Default --list boolean Print out the content of system settings file. False --get text Return value of the key (use OmegaConf notation, e.g. mlcube config --get runners.docker ). None --create_platform , --create-platform tuple Create a new platform instance for this runner. Default runner parameters are used to initialize this new platform. None --remove_platform , --remove-platform text Remove this platform. If this is one of the default platforms (e.g., docker ), it will be recreated (with default values) next time mlcube runs. None --rename_platform , --rename-platform tuple Rename existing platform. If default platform is to be renamed (e.g., docker ), it will be recreated (with default values) next time mlcube runs. None --copy_platform , --copy-platform tuple Copy existing platform. This can be useful for creating new platforms off existing platforms, for instance,creating a new SSH runner configuration that runs MLCubes on a new remote server. None --rename_runner , --rename-runner tuple Rename existing MLCube runner. If platforms exist that reference this runner, users must explicitly provide --update-platforms flag to confirm they want to update platforms' description too. None --remove_runner , --remove-runner text Remove existing runner. If platforms exist that reference this runner, users must explicitly provide --remove-platforms flag to confirm they want to remove platforms too. None --help , -h boolean Show help message and exit. False","title":"config"},{"location":"getting-started/cli/#mlcube-configure","text":"Configure MLCube. Some MLCube projects need to be configured first. For instance, docker-based MLCubes distributed via GitHub with source code most likely will provide a Dockerfile to build a docker image. In this case, the process of building a docker image before MLCube runner can run it, is called a configuration phase. In general, users do not need to run this command manually - MLCube runners should be able to figure out when they need to run it, and will run it as part of mlcube run command. Usage: mlcube configure [OPTIONS] Options: Name Type Description Default --mlcube text Path to an MLCube project. It can be a directory path , or a path to an MLCube configuration file . When it is a directory path, MLCube runtime assumes this directory is the MLCube root directory containing mlcube.yaml file. When it is a file path, this file is assumed to be the MLCube configuration file ( mlcube.yaml ), and a parent directory of this file is considered to be the MLCube root directory. Default value is current directory. None --platform text Platform name to run MLCube on (a platform is a configured instance of an MLCube runner). Multiple platforms are supported, including docker ( Docker and Podman ), singularity ( Singularity ). Other runners are in experimental stage: gcp ( Google Cloud Platform ), k8s ( Kubernetes ), kubeflow ( KubeFlow ), ssh ( SSH runner ). Default is docker . Platforms are defined and configured in MLCube system settings file . docker -P , -p text MLCube configuration parameter is a key-value pair. Must start with -P or '-p'. The dot (.) is used to refer to nested parameters, for instance, -Pdocker.build_strategy=always . These parameters have the highest priority and override any other parameters in system settings and MLCube configuration . None --help , -h boolean Show help message and exit. False","title":"configure"},{"location":"getting-started/cli/#mlcube-create","text":"Create a new Python project from the MLCube cookiecutter template. MLCube uses the cookiecutter library with the mlcube_cookiecutter template. The library is not installed automatically: install it with pip install cookiecutter . Usage: mlcube create [OPTIONS] Options: Name Type Description Default --help , -h boolean Show help message and exit. False","title":"create"},{"location":"getting-started/cli/#mlcube-describe","text":"Describe this MLCube. Usage: mlcube describe [OPTIONS] Options: Name Type Description Default --mlcube text Path to an MLCube project. It can be a directory path , or a path to an MLCube configuration file . When it is a directory path, MLCube runtime assumes this directory is the MLCube root directory containing mlcube.yaml file. When it is a file path, this file is assumed to be the MLCube configuration file ( mlcube.yaml ), and a parent directory of this file is considered to be the MLCube root directory. Default value is current directory. None --help , -h boolean Show help message and exit. False","title":"describe"},{"location":"getting-started/cli/#mlcube-run","text":"Run MLCube task(s). Usage: mlcube run [OPTIONS] Options: Name Type Description Default --mlcube text Path to an MLCube project. It can be a directory path , or a path to an MLCube configuration file . When it is a directory path, MLCube runtime assumes this directory is the MLCube root directory containing mlcube.yaml file. When it is a file path, this file is assumed to be the MLCube configuration file ( mlcube.yaml ), and a parent directory of this file is considered to be the MLCube root directory. Default value is current directory. None --platform text Platform name to run MLCube on (a platform is a configured instance of an MLCube runner). Multiple platforms are supported, including docker ( Docker and Podman ), singularity ( Singularity ). Other runners are in experimental stage: gcp ( Google Cloud Platform ), k8s ( Kubernetes ), kubeflow ( KubeFlow ), ssh ( SSH runner ). Default is docker . Platforms are defined and configured in MLCube system settings file . docker --task text MLCube task name(s) to run, default is main . This parameter can take a list of values, in which case task names are separated with comma (,). None --workspace text Location of a workspace to store input and output artifacts of MLCube tasks . If not specified (None), ${MLCUBE_ROOT}/workspace/ is used. None -P , -p text MLCube configuration parameter is a key-value pair. Must start with -P or '-p'. The dot (.) is used to refer to nested parameters, for instance, -Pdocker.build_strategy=always . These parameters have the highest priority and override any other parameters in system settings and MLCube configuration . None --help , -h boolean Show help message and exit. False","title":"run"},{"location":"getting-started/cli/#mlcube-show_config","text":"Show effective MLCube configuration. Effective MLCube configuration is the one used by one of MLCube runners to run this MLCube. This configuration is built by merging (1) default runner configuration retrieved from system settings, (2) MLCube project configuration and (3) configuration parameters passed by a user on a command line (CONFIG_PARAM). Usage: mlcube show_config [OPTIONS] Options: Name Type Description Default --mlcube text Path to an MLCube project. It can be a directory path , or a path to an MLCube configuration file . When it is a directory path, MLCube runtime assumes this directory is the MLCube root directory containing mlcube.yaml file. When it is a file path, this file is assumed to be the MLCube configuration file ( mlcube.yaml ), and a parent directory of this file is considered to be the MLCube root directory. Default value is current directory. None --platform text Platform name to run MLCube on (a platform is a configured instance of an MLCube runner). Multiple platforms are supported, including docker ( Docker and Podman ), singularity ( Singularity ). Other runners are in experimental stage: gcp ( Google Cloud Platform ), k8s ( Kubernetes ), kubeflow ( KubeFlow ), ssh ( SSH runner ). Default is docker . Platforms are defined and configured in MLCube system settings file . docker --workspace text Location of a workspace to store input and output artifacts of MLCube tasks . If not specified (None), ${MLCUBE_ROOT}/workspace/ is used. None --resolve boolean Resolve MLCube parameters . The mlcube uses OmegaConf library to manage its configuration, including configuration files , system settings files and configuration parameters provided by users on command lines. OmegaConf supports variable interpolation (when one variables depend on other variables, e.g., {'docker.image': 'mlcommons/{name}:${version}'} ). When this flag is set to true, the mlcube computes actual values of all variables. False -P , -p text MLCube configuration parameter is a key-value pair. Must start with -P or '-p'. The dot (.) is used to refer to nested parameters, for instance, -Pdocker.build_strategy=always . These parameters have the highest priority and override any other parameters in system settings and MLCube configuration . None --help , -h boolean Show help message and exit. False","title":"show_config"},{"location":"getting-started/concepts/","text":"MLCube concepts \u00b6 Command Line Arguments \u00b6 MLCube runtime and MLCube runners accept multiple command line arguments. They can be classified into two categories: Fixed command-specific parameters such as --mlcube , --platform and --task for the MLCube's run command, or create_platform and rename_platform for the config command. Parameters that override system settings or MLCube configuration. These parameters start with -P and should follow OmegaConf 's format (MLCube uses this library to manage its settings and configurations). For instance, to override docker runner settings and instruct it to always build MLCube images, one should provide the following command line argument: -Pdocker.build_strategy=always . These command line arguments override system settings and MLCube configuration parameters. Effective MLCube configuration \u00b6 Effective MLCube configuration is the actual configuration that MLCube runners use to run MLCubes. This effective configuration is built using the following algorithm. A platform configuration for a runner is retrieved from system settings (users provide the platform name on a command line by passing --platform=PLATFORM_NAME argument). Then, the MLCube configuration is loaded from the MLCube project to run, and this configuration can override default configuration retrieved from system settings. The source for this configuration is specified by a user on a command line using --mlcube=MLCUBE_PATH argument. The third source of configuration is the command line. Users can provide configuration parameters that override default behavior of a MLCube runner, or default parameters of the MLCube project. These parameters start with -P , for instance, -Pdocker.build_strategy=always . These parameters have the highest priority and override any other parameters loaded so far. MLCube Configuration \u00b6 MLCube Configuration provide MLCube-specific configuration, such as implemented tasks and, optionally, specific platform (hardware) requirements, for instance, GPU and host memory required to run the tasks. This configuration overrides system settings. For MLCubes that are distributed via GitHub (with source files), this configuration is stored in a YAML file with default location being ${MLCUBE_ROOT}/mlcube.yaml . MLCube Configuration Parameter \u00b6 MLCube configuration paramter is a configuration parameter for MLCube runners or MLCube projects that has (usually) a type from the following set: (integer, floating point number, string, bool). Every MLCube runner and all MLCube projects have such parameters, usually organized in a hierarchy. Users can also provide these parameters on a command line when they interact with MLCube runtime to override default values for these parameters. MLCube uses OmegaConf library to manage its configuration. When users provide these parameters on a command line, they need to follow OmegaConf rules, in particular, nested parameters should use . symbol. Also, when providing these parameters on a command line, these parameters must have -P prefix. Several examples: # Overriding top level parameter. Here, the `description` is a parameter in a global namespace. -Pdescription = \"MLCube project description\" # Overriding nested parameter. Here, the `build_strategy` is a parameter defined in the `docker` namespace. -Pdocker.build_strategy = always MLCube Home Directory \u00b6 MLCube home directory is the synonym for MLCube Root Directory . MLCube Runtime \u00b6 The MLCube Runtime term is used to describe the core MLCube library with MLCube runners. MLCube runtime is responsible for managing MLCube system settings and MLCube configurations, and run MLCubes in various environments. MLCube Root Directory \u00b6 MLCube root directory is the directory that contains MLCube configuration file ( mlcube.yaml ). This definition applies to MLCubes that are distributed, for instance, via GitHub. MLCubes \u00b6 The term MLCubes (or MLCube project in singular form) refers to Machine Learning projects packaged and distributed using MLCube stack. Platform \u00b6 A platform is a configured instance of a MLCube runner. Every runner has a default configured instance with the same name as runner. For instance, the MLCube docker runner (named docker ) has a default platform named docker as well. Users may find it useful to have multiple configured instances (platforms) of one MLCube runner. For instance, if a user has personal and corporate accounts in some cloud provider, they can have multiple platforms - one for each account. Users directly interact with platforms via command line argument --platform . System settings provide platform configurations, and users can manually edit system settings to add new platforms, or use MLCube's runtime config command to perform basic operations with system settings, such as creating a new platform. See System Settings description for more detailed explanation of MLCube runners and platforms, and how they relate to each other. Runner \u00b6 MLCube runners are workhorses of MLCube runtime. They run MLCubes in different environments, such as docker and singularity, remote on-prem or cloud compute nodes, and orchestration engines such as Kubernetes and KubeFlow. As part of MLCube ecosystem, we provide multiple MLCube reference runners. Users do not directly interact with MLCube runners, instead they interact with platforms , which are configured instances of MLCube runners. System Settings \u00b6 MLCube System Settings configure MLCube and MLCube runners at a system level. The term system level here implies that these settings are not tied to particular MLCubes (MLCube compliant ML projects). Instead, these settings are used by MLCube runners on every machine where MLCube runtime is configured to use these settings. By default, system settings are stored in a YAML file with default location being ${MLCUBE_ROOT}/mlcube.yaml . The location can be overriden by exporting the MLCUBE_SYSTEM_SETTINGS environment variable. Task \u00b6 MLCube projects expose their functionality via tasks . A task implements one particular function, such as downloading a machine learning dataset, preprocessing this dataset, training a machine learning model, testing a machine learning model or registering a machine learning model with the external model registry. It's up to developers to decide how they want to organize their projects into tasks. A close analogy would be machine learning pipelines composed of multiple steps organized into directed acyclic graph. Tasks in MLCubes are like steps on these pipelines, except that MLCube runtime at this point is not aware about task dependencies, and so the MLCube task model could be described as bag of tasks (similarly to bag of words term used in natural language processing to describe machine learning models that do not take into account positions of words in sentences). The MLCube examples project implements several MLCubes, including MNIST MLCube that implements two tasks: download (download MNIST dataset) and train (train a simple classifier). When users run MLCubes, they can instruct MLCube runtime to execute a particular task by providing --task command line argument: mlcube run --mlcube=. --task=download --platform=docker . MLCube runtime can also accept comma-separated list of tasks, in which case these tasks will be executed in the order users provided them on a command line: mlcube run --mlcube=. --task=download,train --platform=docker . Workspace \u00b6 A workspace is a directory where input and output artifacts are stored. By default, its location is ${MLCUBE_ROOT}/workspace . Users can override this parameter on a command line by providing the --workspace argument. Users need to provide this parameter each time they run MLCube task, even when these tasks are logically grouped into one execution. A better alternative would be to run multiple tasks at the same time (see task section).","title":"MLCube concepts"},{"location":"getting-started/concepts/#mlcube-concepts","text":"","title":"MLCube concepts"},{"location":"getting-started/concepts/#command-line-arguments","text":"MLCube runtime and MLCube runners accept multiple command line arguments. They can be classified into two categories: Fixed command-specific parameters such as --mlcube , --platform and --task for the MLCube's run command, or create_platform and rename_platform for the config command. Parameters that override system settings or MLCube configuration. These parameters start with -P and should follow OmegaConf 's format (MLCube uses this library to manage its settings and configurations). For instance, to override docker runner settings and instruct it to always build MLCube images, one should provide the following command line argument: -Pdocker.build_strategy=always . These command line arguments override system settings and MLCube configuration parameters.","title":"Command Line Arguments"},{"location":"getting-started/concepts/#effective-mlcube-configuration","text":"Effective MLCube configuration is the actual configuration that MLCube runners use to run MLCubes. This effective configuration is built using the following algorithm. A platform configuration for a runner is retrieved from system settings (users provide the platform name on a command line by passing --platform=PLATFORM_NAME argument). Then, the MLCube configuration is loaded from the MLCube project to run, and this configuration can override default configuration retrieved from system settings. The source for this configuration is specified by a user on a command line using --mlcube=MLCUBE_PATH argument. The third source of configuration is the command line. Users can provide configuration parameters that override default behavior of a MLCube runner, or default parameters of the MLCube project. These parameters start with -P , for instance, -Pdocker.build_strategy=always . These parameters have the highest priority and override any other parameters loaded so far.","title":"Effective MLCube configuration"},{"location":"getting-started/concepts/#mlcube-configuration","text":"MLCube Configuration provide MLCube-specific configuration, such as implemented tasks and, optionally, specific platform (hardware) requirements, for instance, GPU and host memory required to run the tasks. This configuration overrides system settings. For MLCubes that are distributed via GitHub (with source files), this configuration is stored in a YAML file with default location being ${MLCUBE_ROOT}/mlcube.yaml .","title":"MLCube Configuration"},{"location":"getting-started/concepts/#mlcube-configuration-parameter","text":"MLCube configuration paramter is a configuration parameter for MLCube runners or MLCube projects that has (usually) a type from the following set: (integer, floating point number, string, bool). Every MLCube runner and all MLCube projects have such parameters, usually organized in a hierarchy. Users can also provide these parameters on a command line when they interact with MLCube runtime to override default values for these parameters. MLCube uses OmegaConf library to manage its configuration. When users provide these parameters on a command line, they need to follow OmegaConf rules, in particular, nested parameters should use . symbol. Also, when providing these parameters on a command line, these parameters must have -P prefix. Several examples: # Overriding top level parameter. Here, the `description` is a parameter in a global namespace. -Pdescription = \"MLCube project description\" # Overriding nested parameter. Here, the `build_strategy` is a parameter defined in the `docker` namespace. -Pdocker.build_strategy = always","title":"MLCube Configuration Parameter"},{"location":"getting-started/concepts/#mlcube-home-directory","text":"MLCube home directory is the synonym for MLCube Root Directory .","title":"MLCube Home Directory"},{"location":"getting-started/concepts/#mlcube-runtime","text":"The MLCube Runtime term is used to describe the core MLCube library with MLCube runners. MLCube runtime is responsible for managing MLCube system settings and MLCube configurations, and run MLCubes in various environments.","title":"MLCube Runtime"},{"location":"getting-started/concepts/#mlcube-root-directory","text":"MLCube root directory is the directory that contains MLCube configuration file ( mlcube.yaml ). This definition applies to MLCubes that are distributed, for instance, via GitHub.","title":"MLCube Root Directory"},{"location":"getting-started/concepts/#mlcubes","text":"The term MLCubes (or MLCube project in singular form) refers to Machine Learning projects packaged and distributed using MLCube stack.","title":"MLCubes"},{"location":"getting-started/concepts/#platform","text":"A platform is a configured instance of a MLCube runner. Every runner has a default configured instance with the same name as runner. For instance, the MLCube docker runner (named docker ) has a default platform named docker as well. Users may find it useful to have multiple configured instances (platforms) of one MLCube runner. For instance, if a user has personal and corporate accounts in some cloud provider, they can have multiple platforms - one for each account. Users directly interact with platforms via command line argument --platform . System settings provide platform configurations, and users can manually edit system settings to add new platforms, or use MLCube's runtime config command to perform basic operations with system settings, such as creating a new platform. See System Settings description for more detailed explanation of MLCube runners and platforms, and how they relate to each other.","title":"Platform"},{"location":"getting-started/concepts/#runner","text":"MLCube runners are workhorses of MLCube runtime. They run MLCubes in different environments, such as docker and singularity, remote on-prem or cloud compute nodes, and orchestration engines such as Kubernetes and KubeFlow. As part of MLCube ecosystem, we provide multiple MLCube reference runners. Users do not directly interact with MLCube runners, instead they interact with platforms , which are configured instances of MLCube runners.","title":"Runner"},{"location":"getting-started/concepts/#system-settings","text":"MLCube System Settings configure MLCube and MLCube runners at a system level. The term system level here implies that these settings are not tied to particular MLCubes (MLCube compliant ML projects). Instead, these settings are used by MLCube runners on every machine where MLCube runtime is configured to use these settings. By default, system settings are stored in a YAML file with default location being ${MLCUBE_ROOT}/mlcube.yaml . The location can be overriden by exporting the MLCUBE_SYSTEM_SETTINGS environment variable.","title":"System Settings"},{"location":"getting-started/concepts/#task","text":"MLCube projects expose their functionality via tasks . A task implements one particular function, such as downloading a machine learning dataset, preprocessing this dataset, training a machine learning model, testing a machine learning model or registering a machine learning model with the external model registry. It's up to developers to decide how they want to organize their projects into tasks. A close analogy would be machine learning pipelines composed of multiple steps organized into directed acyclic graph. Tasks in MLCubes are like steps on these pipelines, except that MLCube runtime at this point is not aware about task dependencies, and so the MLCube task model could be described as bag of tasks (similarly to bag of words term used in natural language processing to describe machine learning models that do not take into account positions of words in sentences). The MLCube examples project implements several MLCubes, including MNIST MLCube that implements two tasks: download (download MNIST dataset) and train (train a simple classifier). When users run MLCubes, they can instruct MLCube runtime to execute a particular task by providing --task command line argument: mlcube run --mlcube=. --task=download --platform=docker . MLCube runtime can also accept comma-separated list of tasks, in which case these tasks will be executed in the order users provided them on a command line: mlcube run --mlcube=. --task=download,train --platform=docker .","title":"Task"},{"location":"getting-started/concepts/#workspace","text":"A workspace is a directory where input and output artifacts are stored. By default, its location is ${MLCUBE_ROOT}/workspace . Users can override this parameter on a command line by providing the --workspace argument. Users need to provide this parameter each time they run MLCube task, even when these tasks are logically grouped into one execution. A better alternative would be to run multiple tasks at the same time (see task section).","title":"Workspace"},{"location":"getting-started/hello-world/","text":"Hello World \u00b6 Hello World MLCube is an example of a Docker-based cube. QuickStart \u00b6 Get started with MLCube Docker runner with below commands. Create python environment \u00b6 virtualenv -p python3.6 ./env && source ./env/bin/activate Install MLCube Docker runner \u00b6 pip install mlcube-docker # Install. mlcube config --get runners # Check it was installed. mlcube config --list # Show system settings for local MLCube runners. Depending on how your local system is configured, it may be required to change the following settings: - platforms.docker.docker (string): A docker executable. Examples are docker , nvidia-docker , sudo docker , podman etc. - platforms.docker.env_args (dictionary) and platforms.docker.build_args (dictionary). Environmental variables for docker run and build phases. Http and https proxy settings can be configured here. A custom configuration could look like: platforms : docker : docker : sudo docker env_args : http_proxy : http://proxy.company.com:8088 https_proxy : https://proxy.company.com.net:8088 build_args : http_proxy : http://proxy.company.com:8088 https_proxy : https://proxy.company.com:8088 Run Hello World MLCube example \u00b6 # The hello_world MLCube is part of the mlcube_examples GitHub repository. git clone https://github.com/mlcommons/mlcube_examples.git && cd ./mlcube_examples/hello_world # Run Hello World MLCube on a local machine with Docker runner. # Show available tasks mlcube describe # Run Hello World example tasks. Very first run can take some time to download (or build) # the MLCube docker image. mlcube run --mlcube=. --task=hello --platform=docker # No output expected. mlcube run --mlcube=. --task=bye --platform=docker # No output expected. cat ./workspace/chats/chat_with_alice.txt # You should some log lines in this file. cat If above mlcube runs fail (with the error message saying there is no docker image available, try to change the system settings file by changing platforms.docker.build_strategy to auto . Setup Docker \u00b6 MLCube Docker runner used Docker runtime, and they must be available in the system. Installation guides for various operating systems can be found here . This example was tested on a system where users are in the docker group and run docker without sudo . To add yourself to a docker group, run the following: sudo groupadd docker # Add the docker group if it doesn't already exist. sudo gpasswd -a ${USER} docker # Add the connected user \"${USER}\" to the docker group. Change # the user name to match your preferred user. sudo service docker restart # Restart the Docker daemon. newgrp docker # Either do a `newgrp docker` or log out/in to activate the # changes to groups. Configuring Hello World MLCube \u00b6 Cubes need to be configured before they can run. MLCube runners do that automatically, and users do not need to run the configure step manually. If for some reason this needs to be done, for instance, to pre-build or pull docker images (if these processes take too much time), MLCube runtime implements configure command. The Hello World cube is a Docker-based cube, and users can configure the MLCube by running the following command: mlcube configure --mlcube=. --platform=docker The Docker runner will build or will pull the docker image for the Hello World cube. As it is mentioned above, this step is optional and is only required when MLCubes need to be rebuilt. This can happen when users change implementation files and want to re-package their ML project into MLCube. In other situations, MLCube runners can auto-detect if configure command needs to be run before running MLCube tasks. Running Hello World MLCube \u00b6 In order to run the Hello World cube, users need to provide the path to the root directory of the cube, platform and task names. Run the following two commands one at a time: cat ./workspace/chats/chat_with_alice.txt mlcube run --mlcube=. --platform=docker --task=hello cat ./workspace/chats/chat_with_alice.txt mlcube run --mlcube=. --platform=docker --task=bye cat ./workspace/chats/chat_with_alice.txt Hello World creates a file workspace/chats/chat_with_alice.txt that contains the following: [2020-09-03 09:13:14.236945] Hi, Alice! Nice to meet you. [2020-09-03 09:13:20.749831] Bye, Alice! It was great talking to you. Modifying MLCube tasks \u00b6 Override parameters on a command line \u00b6 One way to change the parameters of MLCubes is to override them on a command line. Create a new file workspace/names/mary.txt with the following content: Mary . Then, run the following: mlcube run --mlcube = . --platform = docker --task = hello name = names/mary.txt chat = chats/chat_with_mary.txt cat workspace/chats/chat_with_mary.txt mlcube run --mlcube = . --platform = docker --task = bye name = names/mary.txt chat = chats/chat_with_mary.txt cat workspace/chats/chat_with_mary.txt You should observe the output similar to this one: [ 2021 -09-30 18 :49:46.896509 ] Hi, Mary! Nice to meet you. [ 2021 -09-30 18 :49:56.883266 ] Bye, Mary! It was great talking to you. Providing a better greeting message \u00b6 Because how Hello World cube was implemented, the greeting message is always the following: Nice to meet you. . We will update the implementation so that if this is not the first time Alice says hello , the MLCube will respond: Nice to see you again. . Modify the file hello_world.py . Update the function named get_greeting_message on line 14. It should have the following implementation: import os def get_greeting_message ( chat_file : str ) -> str : return \"Nice to meet you.\" if not os . path . exists ( chat_file ) else \"Nice to see you again.\" Reconfigure the MLCube: mlcube configure --mlcube=. --platform=docker And run two hello tasks again: rm ./workspace/chats/chat_with_alice.txt mlcube run --mlcube = . --platform = docker --task = hello,bye mlcube run --mlcube = . --platform = docker --task = hello,bye cat ./workspace/chats/chat_with_alice.txt The MLCube recognized it was not the first time it talked to Alice, and changed the greeting: [2021-09-30 20:04:36.977032] Hi, Alice! Nice to meet you. [2021-09-30 20:04:40.851157] Bye, Alice! It was great talking to you. [2021-09-30 20:04:47.228554] Hi, Alice! Nice to see you again. [2021-09-30 20:04:51.031609] Bye, Alice! It was great talking to you.","title":"Hello World"},{"location":"getting-started/hello-world/#hello-world","text":"Hello World MLCube is an example of a Docker-based cube.","title":"Hello World"},{"location":"getting-started/hello-world/#quickstart","text":"Get started with MLCube Docker runner with below commands.","title":"QuickStart"},{"location":"getting-started/hello-world/#create-python-environment","text":"virtualenv -p python3.6 ./env && source ./env/bin/activate","title":"Create python environment"},{"location":"getting-started/hello-world/#install-mlcube-docker-runner","text":"pip install mlcube-docker # Install. mlcube config --get runners # Check it was installed. mlcube config --list # Show system settings for local MLCube runners. Depending on how your local system is configured, it may be required to change the following settings: - platforms.docker.docker (string): A docker executable. Examples are docker , nvidia-docker , sudo docker , podman etc. - platforms.docker.env_args (dictionary) and platforms.docker.build_args (dictionary). Environmental variables for docker run and build phases. Http and https proxy settings can be configured here. A custom configuration could look like: platforms : docker : docker : sudo docker env_args : http_proxy : http://proxy.company.com:8088 https_proxy : https://proxy.company.com.net:8088 build_args : http_proxy : http://proxy.company.com:8088 https_proxy : https://proxy.company.com:8088","title":"Install MLCube Docker runner"},{"location":"getting-started/hello-world/#run-hello-world-mlcube-example","text":"# The hello_world MLCube is part of the mlcube_examples GitHub repository. git clone https://github.com/mlcommons/mlcube_examples.git && cd ./mlcube_examples/hello_world # Run Hello World MLCube on a local machine with Docker runner. # Show available tasks mlcube describe # Run Hello World example tasks. Very first run can take some time to download (or build) # the MLCube docker image. mlcube run --mlcube=. --task=hello --platform=docker # No output expected. mlcube run --mlcube=. --task=bye --platform=docker # No output expected. cat ./workspace/chats/chat_with_alice.txt # You should some log lines in this file. cat If above mlcube runs fail (with the error message saying there is no docker image available, try to change the system settings file by changing platforms.docker.build_strategy to auto .","title":"Run Hello World MLCube example"},{"location":"getting-started/hello-world/#setup-docker","text":"MLCube Docker runner used Docker runtime, and they must be available in the system. Installation guides for various operating systems can be found here . This example was tested on a system where users are in the docker group and run docker without sudo . To add yourself to a docker group, run the following: sudo groupadd docker # Add the docker group if it doesn't already exist. sudo gpasswd -a ${USER} docker # Add the connected user \"${USER}\" to the docker group. Change # the user name to match your preferred user. sudo service docker restart # Restart the Docker daemon. newgrp docker # Either do a `newgrp docker` or log out/in to activate the # changes to groups.","title":"Setup Docker"},{"location":"getting-started/hello-world/#configuring-hello-world-mlcube","text":"Cubes need to be configured before they can run. MLCube runners do that automatically, and users do not need to run the configure step manually. If for some reason this needs to be done, for instance, to pre-build or pull docker images (if these processes take too much time), MLCube runtime implements configure command. The Hello World cube is a Docker-based cube, and users can configure the MLCube by running the following command: mlcube configure --mlcube=. --platform=docker The Docker runner will build or will pull the docker image for the Hello World cube. As it is mentioned above, this step is optional and is only required when MLCubes need to be rebuilt. This can happen when users change implementation files and want to re-package their ML project into MLCube. In other situations, MLCube runners can auto-detect if configure command needs to be run before running MLCube tasks.","title":"Configuring Hello World MLCube"},{"location":"getting-started/hello-world/#running-hello-world-mlcube","text":"In order to run the Hello World cube, users need to provide the path to the root directory of the cube, platform and task names. Run the following two commands one at a time: cat ./workspace/chats/chat_with_alice.txt mlcube run --mlcube=. --platform=docker --task=hello cat ./workspace/chats/chat_with_alice.txt mlcube run --mlcube=. --platform=docker --task=bye cat ./workspace/chats/chat_with_alice.txt Hello World creates a file workspace/chats/chat_with_alice.txt that contains the following: [2020-09-03 09:13:14.236945] Hi, Alice! Nice to meet you. [2020-09-03 09:13:20.749831] Bye, Alice! It was great talking to you.","title":"Running Hello World MLCube"},{"location":"getting-started/hello-world/#modifying-mlcube-tasks","text":"","title":"Modifying MLCube tasks"},{"location":"getting-started/hello-world/#override-parameters-on-a-command-line","text":"One way to change the parameters of MLCubes is to override them on a command line. Create a new file workspace/names/mary.txt with the following content: Mary . Then, run the following: mlcube run --mlcube = . --platform = docker --task = hello name = names/mary.txt chat = chats/chat_with_mary.txt cat workspace/chats/chat_with_mary.txt mlcube run --mlcube = . --platform = docker --task = bye name = names/mary.txt chat = chats/chat_with_mary.txt cat workspace/chats/chat_with_mary.txt You should observe the output similar to this one: [ 2021 -09-30 18 :49:46.896509 ] Hi, Mary! Nice to meet you. [ 2021 -09-30 18 :49:56.883266 ] Bye, Mary! It was great talking to you.","title":"Override parameters on a command line"},{"location":"getting-started/hello-world/#providing-a-better-greeting-message","text":"Because how Hello World cube was implemented, the greeting message is always the following: Nice to meet you. . We will update the implementation so that if this is not the first time Alice says hello , the MLCube will respond: Nice to see you again. . Modify the file hello_world.py . Update the function named get_greeting_message on line 14. It should have the following implementation: import os def get_greeting_message ( chat_file : str ) -> str : return \"Nice to meet you.\" if not os . path . exists ( chat_file ) else \"Nice to see you again.\" Reconfigure the MLCube: mlcube configure --mlcube=. --platform=docker And run two hello tasks again: rm ./workspace/chats/chat_with_alice.txt mlcube run --mlcube = . --platform = docker --task = hello,bye mlcube run --mlcube = . --platform = docker --task = hello,bye cat ./workspace/chats/chat_with_alice.txt The MLCube recognized it was not the first time it talked to Alice, and changed the greeting: [2021-09-30 20:04:36.977032] Hi, Alice! Nice to meet you. [2021-09-30 20:04:40.851157] Bye, Alice! It was great talking to you. [2021-09-30 20:04:47.228554] Hi, Alice! Nice to see you again. [2021-09-30 20:04:51.031609] Bye, Alice! It was great talking to you.","title":"Providing a better greeting message"},{"location":"getting-started/mnist/","text":"MNIST \u00b6 The MNIST dataset is a collection of 60,000 handwritten digits widely used for training statistical, Machine Learning (ML) and Deep Learning (DL) models. The MNIST MLCube example demonstrates how data scientists, ML and DL researchers and developers can distribute their ML projects (including training, validation and inference code) as MLCube cubes. MLCube establishes a standard to package user workloads, and provides unified command line interface. In addition, MLCube provides a number of reference runners - python packages that can run cubes on different platforms including Docker , Singularity , KubeFlow and several others. A data scientist has been working on a machine learning project. The goal is to train a simple neural network to classify the collection of 60,000 small images into 10 classes. The source files for this MNIST example can be found on GitHub in MLCube Example repository . MNIST training code \u00b6 Training an ML model is a process involving multiple steps such as downloading data, analyzing and cleaning data, splitting data into train/validation/test data sets, running hyper-parameter optimization experiments and performing final model testing. MNIST dataset is a relatively small and well studied dataset that provides standard train/test split. In this simple example a developer needs to implement two steps - (1) downloading data and (2) training a model. We call these steps as tasks . Each task requires several parameters, such as a URL of the data set that we need to download, location on a local disk where the data set will be downloaded to, path to a directory that will contain training artifacts such as log files, training snapshots and Machine Learning models. We can characterize these two tasks in the following way: Download task: Inputs : A yaml file ( data_config ) with two parameters - dataset URI and dataset hash. Outputs : Directory to serialize the data set ( data_dir ) and directory to serialize log files ( log_dir ). Training task: Inputs : Directory with MNIST data set ( data_dir ), training hyper-parameters defined in a file ( train_config ). Outputs : Directory to store training results ( model_dir ) and directory to store log files ( log_dir ). We have intentionally made all input/output parameters to be file system artifacts. By doing so, we support reproducibility. Instead of command line arguments that can easily be lost, we store them in files. There are many ways to implement the MNIST example. For simplicity, we assume the following: We use one python file. Task name (download, train) is a command line positional parameter. Both tasks write logs, so it makes sense to add a parameter that defines a directory for log files. The download task accepts additional data directory parameter. The train task accepts such parameters as data and model directories, path to a file with hyper-parameter. Configurable hyper-parameters are: (1) optimizer name, (2) number of training epochs and (3) global batch size. Then, our implementation could look like this. Parse command line arguments and identify a task to run. If it is the download task, call a function that downloads data sets. If it is the train task, train a model. This is sort of single entrypoint implementation where we run one script asking to perform various tasks. We run our script (mnist.py) in the following way: python mnist.py download --data_config=PATH --data_dir=PATH --log_dir=PATH python mnist.py train --train_config=PATH --data_dir=PATH --model_dir=PATH --log_dir=PATH MLCube implementation \u00b6 Packaging our MNIST training script as a MLCube is done in several steps. We will be using a directory-based cube where a directory is structured in a certain way and contains specific files that make it MLCube compliant. We need to create an empty directory on a local disk. Let's assume we call it mnist and we'll use {MLCUBE_ROOT} to denote a full path to this directory. This is called an MLCube root directory. At this point this directory is empty: mnist/ Build location \u00b6 The MLCube root directory will contain project source files, resources required for training, other files to recreate run time (such as requirements.txt, docker and singularity recipes etc.). We need to copy two files: mnist.py that implements training and requirements.txt that lists python dependencies. By doing so, we are enforcing reproducibility. A developer of this MLCube wants to make it easier to run their training workload in a great variety of environments including universities, commercial companies, HPC-friendly organizations such as national labs. One way to achieve it is to use container runtime such as docker or singularity. So, we'll provide both docker file and singularity recipe that we'll put into the MLCube root directory as well. Thus, we'll make this directory a build context. For reasons that we will explain later, we also need to add .dockerignore file (that contains single line - workspace/ ). The MLCube directory now looks like: mnist/ .dockerignore Dockerfile mnist.py requirements.txt Singularity.recipe A good test at this point would be to ensure that project is runnable from the build directory, and docker and singularity images can be built. MLCube definition file \u00b6 At this point we are ready to create a cube definition file. This is the first definition file that makes a folder to be an MLCube folder. This is a YAML file that provides information such as name, author, version, named as mlcube.yaml and located in the cube root directory . The most important section is the one that lists what tasks are implemented in this cube: # Name of this MLCube. name : mnist # Brief description for this MLCube. description : MLCommons MNIST MLCube example # List of authors/developers. authors : - name : \"First Second\" email : \"first.second@company.com\" org : \"Company Inc.\" # Platform description. This is where users can specify MLCube resource requirements, such as # number of accelerators, memory and disk requirements etc. The exact structure and intended # usage of information in this section is work in progress. This section is optional now. platform : accelerator_count : 0 accelerator_maker : NVIDIA accelerator_model : A100-80GB host_memory_gb : 40 need_internet_access : True host_disk_space_gb : 100 # Configuration for docker runner (additional options can be configured in system settings file). docker : image : mlcommons/mnist:0.0.1 # Configuration for singularity runner (additional options can be configured in system settings # file). singularity : image : mnist-0.0.1.simg # Section where MLCube tasks are defined. tasks : # `Download` task. It has one input and two output parameters. download : parameters : inputs : { data_config : data.yaml } outputs : { data_dir : data/ , log_dir : logs/ } # `Train` task. It has two input and two output parameters. train : parameters : inputs : { data_dir : data/ , train_config : train.yaml } outputs : { log_dir : logs/ , model_dir : model/ } At this point, the directory looks like: mnist/ .dockerignore Dockerfile mlcube.yaml mnist.py requirements.txt Singularity.recipe Workspace \u00b6 The workspace is a directory inside cube ( workspace ) where, by default, input/output file system artifacts are stored. There are multiple reasons to have one. One is to formally have default place for data sets, configuration and log files etc. Having all these parameters in one place makes it simpler to run cubes on remote hosts and then sync results back to users' local machines. We need to be able to provide URI and hash of the MNIST dataset, collection of hyper-parameters and formally define a directory to store logs, models and MNIST data set. To do so, we create the directory tree workspace/ , and then create two files with the following content ( data.yaml ): uri : https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz hash : 731c5ac602752760c8e48fbffcf8c3b850d9dc2a2aedcf2cc48468fc17b673d1 and train.yaml : optimizer : \"adam\" train_epochs : 5 batch_size : 32 At this point, the cube directory looks like: mnist/ workspace/ data.yaml train.yaml .dockerignore Dockerfile mlcube.yaml mnist.py requirements.txt Singularity.recipe MNIST MLCube directory structure summary \u00b6 mnist/ workspace/ # Default location for data sets, logs, models, parameter files. data.yaml # URI and hash of MNIST dataset. train.yaml # Train hyper-parameters. .dockerignore # Docker ignore file that prevents workspace directory to be sent to docker server. Dockerfile # Docker recipe. mlcube.yaml # MLCube definition file. mnist.py # Python source code training simple neural network using MNIST data set. requirements.txt # Python project dependencies. Singularity.recipe # Singularity recipe. Running MNIST MLCube \u00b6 We need to set up the Python virtual environment. These are the steps outlined in the Introduction section except we do not clone GitHub repository with the example MLCube cubes. # Create Python Virtual Environment virtualenv -p python3.6 ./env && source ./env/bin/activate # Install MLCube Docker and Singularity runners pip install mlcube-docker mlcube-singularity Before running MNIST cube below, it is probably a good idea to remove tasks' outputs from previous runs that are located in the workspace directory. All directories except can be removed. Docker Runner \u00b6 Configure MNIST cube (this is optional step, docker runner checks if image exists, and if it does not, runs configure phase automatically): mlcube configure --mlcube=. --platform=docker Run two tasks - download (download data) and train (train tiny neural network): mlcube run --mlcube=. --platform=docker --task=download mlcube run --mlcube=. --platform=docker --task=train Singularity Runner \u00b6 Configure MNIST cube: mlcube configure --mlcube=. --platform=singularity Run two tasks - download (download data) and train (train tiny neural network): mlcube run --mlcube=. --platform=singularity --task=download mlcube run --mlcube=. --platform=singularity --task=train","title":"MNIST"},{"location":"getting-started/mnist/#mnist","text":"The MNIST dataset is a collection of 60,000 handwritten digits widely used for training statistical, Machine Learning (ML) and Deep Learning (DL) models. The MNIST MLCube example demonstrates how data scientists, ML and DL researchers and developers can distribute their ML projects (including training, validation and inference code) as MLCube cubes. MLCube establishes a standard to package user workloads, and provides unified command line interface. In addition, MLCube provides a number of reference runners - python packages that can run cubes on different platforms including Docker , Singularity , KubeFlow and several others. A data scientist has been working on a machine learning project. The goal is to train a simple neural network to classify the collection of 60,000 small images into 10 classes. The source files for this MNIST example can be found on GitHub in MLCube Example repository .","title":"MNIST"},{"location":"getting-started/mnist/#mnist-training-code","text":"Training an ML model is a process involving multiple steps such as downloading data, analyzing and cleaning data, splitting data into train/validation/test data sets, running hyper-parameter optimization experiments and performing final model testing. MNIST dataset is a relatively small and well studied dataset that provides standard train/test split. In this simple example a developer needs to implement two steps - (1) downloading data and (2) training a model. We call these steps as tasks . Each task requires several parameters, such as a URL of the data set that we need to download, location on a local disk where the data set will be downloaded to, path to a directory that will contain training artifacts such as log files, training snapshots and Machine Learning models. We can characterize these two tasks in the following way: Download task: Inputs : A yaml file ( data_config ) with two parameters - dataset URI and dataset hash. Outputs : Directory to serialize the data set ( data_dir ) and directory to serialize log files ( log_dir ). Training task: Inputs : Directory with MNIST data set ( data_dir ), training hyper-parameters defined in a file ( train_config ). Outputs : Directory to store training results ( model_dir ) and directory to store log files ( log_dir ). We have intentionally made all input/output parameters to be file system artifacts. By doing so, we support reproducibility. Instead of command line arguments that can easily be lost, we store them in files. There are many ways to implement the MNIST example. For simplicity, we assume the following: We use one python file. Task name (download, train) is a command line positional parameter. Both tasks write logs, so it makes sense to add a parameter that defines a directory for log files. The download task accepts additional data directory parameter. The train task accepts such parameters as data and model directories, path to a file with hyper-parameter. Configurable hyper-parameters are: (1) optimizer name, (2) number of training epochs and (3) global batch size. Then, our implementation could look like this. Parse command line arguments and identify a task to run. If it is the download task, call a function that downloads data sets. If it is the train task, train a model. This is sort of single entrypoint implementation where we run one script asking to perform various tasks. We run our script (mnist.py) in the following way: python mnist.py download --data_config=PATH --data_dir=PATH --log_dir=PATH python mnist.py train --train_config=PATH --data_dir=PATH --model_dir=PATH --log_dir=PATH","title":"MNIST training code"},{"location":"getting-started/mnist/#mlcube-implementation","text":"Packaging our MNIST training script as a MLCube is done in several steps. We will be using a directory-based cube where a directory is structured in a certain way and contains specific files that make it MLCube compliant. We need to create an empty directory on a local disk. Let's assume we call it mnist and we'll use {MLCUBE_ROOT} to denote a full path to this directory. This is called an MLCube root directory. At this point this directory is empty: mnist/","title":"MLCube implementation"},{"location":"getting-started/mnist/#build-location","text":"The MLCube root directory will contain project source files, resources required for training, other files to recreate run time (such as requirements.txt, docker and singularity recipes etc.). We need to copy two files: mnist.py that implements training and requirements.txt that lists python dependencies. By doing so, we are enforcing reproducibility. A developer of this MLCube wants to make it easier to run their training workload in a great variety of environments including universities, commercial companies, HPC-friendly organizations such as national labs. One way to achieve it is to use container runtime such as docker or singularity. So, we'll provide both docker file and singularity recipe that we'll put into the MLCube root directory as well. Thus, we'll make this directory a build context. For reasons that we will explain later, we also need to add .dockerignore file (that contains single line - workspace/ ). The MLCube directory now looks like: mnist/ .dockerignore Dockerfile mnist.py requirements.txt Singularity.recipe A good test at this point would be to ensure that project is runnable from the build directory, and docker and singularity images can be built.","title":"Build location"},{"location":"getting-started/mnist/#mlcube-definition-file","text":"At this point we are ready to create a cube definition file. This is the first definition file that makes a folder to be an MLCube folder. This is a YAML file that provides information such as name, author, version, named as mlcube.yaml and located in the cube root directory . The most important section is the one that lists what tasks are implemented in this cube: # Name of this MLCube. name : mnist # Brief description for this MLCube. description : MLCommons MNIST MLCube example # List of authors/developers. authors : - name : \"First Second\" email : \"first.second@company.com\" org : \"Company Inc.\" # Platform description. This is where users can specify MLCube resource requirements, such as # number of accelerators, memory and disk requirements etc. The exact structure and intended # usage of information in this section is work in progress. This section is optional now. platform : accelerator_count : 0 accelerator_maker : NVIDIA accelerator_model : A100-80GB host_memory_gb : 40 need_internet_access : True host_disk_space_gb : 100 # Configuration for docker runner (additional options can be configured in system settings file). docker : image : mlcommons/mnist:0.0.1 # Configuration for singularity runner (additional options can be configured in system settings # file). singularity : image : mnist-0.0.1.simg # Section where MLCube tasks are defined. tasks : # `Download` task. It has one input and two output parameters. download : parameters : inputs : { data_config : data.yaml } outputs : { data_dir : data/ , log_dir : logs/ } # `Train` task. It has two input and two output parameters. train : parameters : inputs : { data_dir : data/ , train_config : train.yaml } outputs : { log_dir : logs/ , model_dir : model/ } At this point, the directory looks like: mnist/ .dockerignore Dockerfile mlcube.yaml mnist.py requirements.txt Singularity.recipe","title":"MLCube definition file"},{"location":"getting-started/mnist/#workspace","text":"The workspace is a directory inside cube ( workspace ) where, by default, input/output file system artifacts are stored. There are multiple reasons to have one. One is to formally have default place for data sets, configuration and log files etc. Having all these parameters in one place makes it simpler to run cubes on remote hosts and then sync results back to users' local machines. We need to be able to provide URI and hash of the MNIST dataset, collection of hyper-parameters and formally define a directory to store logs, models and MNIST data set. To do so, we create the directory tree workspace/ , and then create two files with the following content ( data.yaml ): uri : https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz hash : 731c5ac602752760c8e48fbffcf8c3b850d9dc2a2aedcf2cc48468fc17b673d1 and train.yaml : optimizer : \"adam\" train_epochs : 5 batch_size : 32 At this point, the cube directory looks like: mnist/ workspace/ data.yaml train.yaml .dockerignore Dockerfile mlcube.yaml mnist.py requirements.txt Singularity.recipe","title":"Workspace"},{"location":"getting-started/mnist/#mnist-mlcube-directory-structure-summary","text":"mnist/ workspace/ # Default location for data sets, logs, models, parameter files. data.yaml # URI and hash of MNIST dataset. train.yaml # Train hyper-parameters. .dockerignore # Docker ignore file that prevents workspace directory to be sent to docker server. Dockerfile # Docker recipe. mlcube.yaml # MLCube definition file. mnist.py # Python source code training simple neural network using MNIST data set. requirements.txt # Python project dependencies. Singularity.recipe # Singularity recipe.","title":"MNIST MLCube directory structure summary"},{"location":"getting-started/mnist/#running-mnist-mlcube","text":"We need to set up the Python virtual environment. These are the steps outlined in the Introduction section except we do not clone GitHub repository with the example MLCube cubes. # Create Python Virtual Environment virtualenv -p python3.6 ./env && source ./env/bin/activate # Install MLCube Docker and Singularity runners pip install mlcube-docker mlcube-singularity Before running MNIST cube below, it is probably a good idea to remove tasks' outputs from previous runs that are located in the workspace directory. All directories except can be removed.","title":"Running MNIST MLCube"},{"location":"getting-started/mnist/#docker-runner","text":"Configure MNIST cube (this is optional step, docker runner checks if image exists, and if it does not, runs configure phase automatically): mlcube configure --mlcube=. --platform=docker Run two tasks - download (download data) and train (train tiny neural network): mlcube run --mlcube=. --platform=docker --task=download mlcube run --mlcube=. --platform=docker --task=train","title":"Docker Runner"},{"location":"getting-started/mnist/#singularity-runner","text":"Configure MNIST cube: mlcube configure --mlcube=. --platform=singularity Run two tasks - download (download data) and train (train tiny neural network): mlcube run --mlcube=. --platform=singularity --task=download mlcube run --mlcube=. --platform=singularity --task=train","title":"Singularity Runner"},{"location":"getting-started/system-settings/","text":"MLCube System Settings \u00b6 MLCube system settings configure MLCube and MLCube runners at a system level. The term system level here implies that these settings are not tied to particular MLCubes (MLCube compliant ML projects). Instead, these settings are used by MLCube runners on every machine where MLCube runtime is configured to use these settings. Introduction \u00b6 When MLCube runners run MLCubes, they need to know not only the content of MLCubes (tasks that MLCubes provide), but also non-standard or custom settings of a user environment. Effective MLCube configuration that MLCube runners end up using is constructed by merging configurations from the following sources: System settings provide non-standard and/or user-specific parameters for MLCube runners. For instance, in system settings users can indicate that they are required to use sudo to run docker. Or they can configure MLCube SSH or GCP (Google Cloud Platform) runners with their credentials to be able to run MLCubes on specific remote servers, either on-prem, or in the cloud. MLCube configuration provide MLCube-specific configuration, such as implemented tasks and, optionally, specific platform (hardware) requirements, for instance, GPU and host memory required to run the tasks. This configuration overrides system settings. Command line parameters that users provide when they run MLCubes. These parameters have the highest priority and override system settings and MLCube configuration. Location \u00b6 MLCube system settings are stored in a YAML file. Default location of this file is ${HOME}/mlcube.yaml . This file is created or updated every time users run any of MLCube commands. When users install a new MLCube runner (for instance, the singularity runner pip install mlcube-singularity ), MLCube will update the system settings file with this new runner next time MLCube runs. Users can directly modify this file. In addition, MLCube runtime provides config command ( mlcube config --help ) to perform typical operations, such as creating a new MLCube runner configuration off existing one. Users can override the location of this file by defining MLCUBE_SYSTEM_SETTINGS environment variable. MLCube System Settings \u00b6 The MLCube system settings are stored in a YAML file. This file has the following schema: runners : # A dictionary with metadata on installed MLCube runners. This section is updated (if # necessary) every time MLCube runs (this means that this section is not updated once # a new runner is installed). Every key in this dictionary is a runner name (must be # unique across all MLCube runners), and every value is (usually) a dictionary providing # runner metadata. In general, it is runner-specific. This section does not provide a # specific configuration for instances of MLCube runners, and users should not modify # content of this section - it is maintained automatically by MLCube runtime. docker : # MLCube provides several reference runners including docker and singularity runners. # All reference runners are implemented in Python and are distributed as separate python # packages on pypi (e.g., `pip install mlcube-docker`). All these reference runners use # the same metadata schema. Their metadata is a dictionary with just one field - `pkg`. # Names of MLCube runners in this section are not directly exposed to users via command # line API. pkg : mlcube_docker # All MLCube reference runners are described with a dictionary with one field (`pkg`) # that points to a Python package name. platforms : # This section (a dictionary) configures instances of MLCube runners. Why there might be # more than one instance of a particular runner? For instance, users might have two Google # Cloud Platform accounts - personal and corporate. Or they might have access to a number # of on-prem compute nodes via ssh, and so they will have respective number of MLCube SSH # runner instances configured here. There is always a default MLCube runner instance that # has the same name as the runner itself (e.g., for Docker runner the name of a default # MLCube docker runner is `docker`). This default section is created automatically by # MLCube runtime if it does not exist. # Every MLCube runner has its own schema (see MLCube runners documentation) with its own # unique set of configuration parameters. # Names of MLCube runner instances defined here are directly exposed to users via command # line argument `--platform`: # - By default, a default MLCube runner instance is configured with the same name as # its MLCube runner class name: docker, singularity etc. # - When users configure their own unique MLCube runner instances (either via `mlcube # config create_platform` command, or manually modifying this file(*)), these instances # become available to use, i.e., something like is possible: # $ mlcube run --mlcube=. --task=train --platform=my_mlcube_runner_instance_name # (*): To configure a new runner instance manually, duplicate default configuration with # a new name and change its parameters. singularity : # This is the example of a default configuration for a MLCube reference singularity runner. # This runner instance, as any other instance, defines the `runner` key which servers as # a foreign key to the `runners` section. runner : singularity # MLCube runner class (defined in `runners` section). image : ${singularity.image} # Image name, usually defined in MLCube configuration file. image_dir : ${runtime.workspace}/.image # Default build directory for MLCubes distributed with sources. singularity : singularity # Singularity executable. build_args : --fakeroot # Build arguments. build_file : Singularity.recipe # Default Singularity build file for MLCubes distributed with sources singularity-1.5.3 : # This is an example of another MLCube singularity runner instance. Maybe, a user has # an outdated version that requires sudo and does not support --fakeroot argument. # Then, this user use this name on a command line to run MLCubes with singularity runner: # $ mlcube run --mlcube=. --task=train --platform=singularity-1.5.3 # BTW, users can create this section by running the following command (they need to edit # it manually though anyway): # $ mlcube config create_platform singularity singularity-1.5.3 runner : singularity image : ${singularity.image} image_dir : ${runtime.workspace}/.image singularity : sudo singularity build_args : build_file : Singularity.recipe","title":"System Settings"},{"location":"getting-started/system-settings/#mlcube-system-settings","text":"MLCube system settings configure MLCube and MLCube runners at a system level. The term system level here implies that these settings are not tied to particular MLCubes (MLCube compliant ML projects). Instead, these settings are used by MLCube runners on every machine where MLCube runtime is configured to use these settings.","title":"MLCube System Settings"},{"location":"getting-started/system-settings/#introduction","text":"When MLCube runners run MLCubes, they need to know not only the content of MLCubes (tasks that MLCubes provide), but also non-standard or custom settings of a user environment. Effective MLCube configuration that MLCube runners end up using is constructed by merging configurations from the following sources: System settings provide non-standard and/or user-specific parameters for MLCube runners. For instance, in system settings users can indicate that they are required to use sudo to run docker. Or they can configure MLCube SSH or GCP (Google Cloud Platform) runners with their credentials to be able to run MLCubes on specific remote servers, either on-prem, or in the cloud. MLCube configuration provide MLCube-specific configuration, such as implemented tasks and, optionally, specific platform (hardware) requirements, for instance, GPU and host memory required to run the tasks. This configuration overrides system settings. Command line parameters that users provide when they run MLCubes. These parameters have the highest priority and override system settings and MLCube configuration.","title":"Introduction"},{"location":"getting-started/system-settings/#location","text":"MLCube system settings are stored in a YAML file. Default location of this file is ${HOME}/mlcube.yaml . This file is created or updated every time users run any of MLCube commands. When users install a new MLCube runner (for instance, the singularity runner pip install mlcube-singularity ), MLCube will update the system settings file with this new runner next time MLCube runs. Users can directly modify this file. In addition, MLCube runtime provides config command ( mlcube config --help ) to perform typical operations, such as creating a new MLCube runner configuration off existing one. Users can override the location of this file by defining MLCUBE_SYSTEM_SETTINGS environment variable.","title":"Location"},{"location":"getting-started/system-settings/#mlcube-system-settings_1","text":"The MLCube system settings are stored in a YAML file. This file has the following schema: runners : # A dictionary with metadata on installed MLCube runners. This section is updated (if # necessary) every time MLCube runs (this means that this section is not updated once # a new runner is installed). Every key in this dictionary is a runner name (must be # unique across all MLCube runners), and every value is (usually) a dictionary providing # runner metadata. In general, it is runner-specific. This section does not provide a # specific configuration for instances of MLCube runners, and users should not modify # content of this section - it is maintained automatically by MLCube runtime. docker : # MLCube provides several reference runners including docker and singularity runners. # All reference runners are implemented in Python and are distributed as separate python # packages on pypi (e.g., `pip install mlcube-docker`). All these reference runners use # the same metadata schema. Their metadata is a dictionary with just one field - `pkg`. # Names of MLCube runners in this section are not directly exposed to users via command # line API. pkg : mlcube_docker # All MLCube reference runners are described with a dictionary with one field (`pkg`) # that points to a Python package name. platforms : # This section (a dictionary) configures instances of MLCube runners. Why there might be # more than one instance of a particular runner? For instance, users might have two Google # Cloud Platform accounts - personal and corporate. Or they might have access to a number # of on-prem compute nodes via ssh, and so they will have respective number of MLCube SSH # runner instances configured here. There is always a default MLCube runner instance that # has the same name as the runner itself (e.g., for Docker runner the name of a default # MLCube docker runner is `docker`). This default section is created automatically by # MLCube runtime if it does not exist. # Every MLCube runner has its own schema (see MLCube runners documentation) with its own # unique set of configuration parameters. # Names of MLCube runner instances defined here are directly exposed to users via command # line argument `--platform`: # - By default, a default MLCube runner instance is configured with the same name as # its MLCube runner class name: docker, singularity etc. # - When users configure their own unique MLCube runner instances (either via `mlcube # config create_platform` command, or manually modifying this file(*)), these instances # become available to use, i.e., something like is possible: # $ mlcube run --mlcube=. --task=train --platform=my_mlcube_runner_instance_name # (*): To configure a new runner instance manually, duplicate default configuration with # a new name and change its parameters. singularity : # This is the example of a default configuration for a MLCube reference singularity runner. # This runner instance, as any other instance, defines the `runner` key which servers as # a foreign key to the `runners` section. runner : singularity # MLCube runner class (defined in `runners` section). image : ${singularity.image} # Image name, usually defined in MLCube configuration file. image_dir : ${runtime.workspace}/.image # Default build directory for MLCubes distributed with sources. singularity : singularity # Singularity executable. build_args : --fakeroot # Build arguments. build_file : Singularity.recipe # Default Singularity build file for MLCubes distributed with sources singularity-1.5.3 : # This is an example of another MLCube singularity runner instance. Maybe, a user has # an outdated version that requires sudo and does not support --fakeroot argument. # Then, this user use this name on a command line to run MLCubes with singularity runner: # $ mlcube run --mlcube=. --task=train --platform=singularity-1.5.3 # BTW, users can create this section by running the following command (they need to edit # it manually though anyway): # $ mlcube config create_platform singularity singularity-1.5.3 runner : singularity image : ${singularity.image} image_dir : ${runtime.workspace}/.image singularity : sudo singularity build_args : build_file : Singularity.recipe","title":"MLCube System Settings"},{"location":"runners/","text":"Runners \u00b6 MLCube runners run MLCube cubes on one or multiple platforms. Examples of platforms are Docker and Singularity containers, Kubernetes, remote hosts, virtual machines in the cloud, etc. Every runner has a fixed set of configuration parameters that users can change to configure MLCubes and runners for their environments. Concretely, runners can take information from three different sources: - MLCube configuration files that are located in the root directory of each file-system based MLCube. Parameters in these files configure generic parameters common for all environments, such as for instance, docker image names. - MLCube system settings file that is located (by default) in the user home directory ( ~/mlcube.yaml ). This file is created automatically, and can be used to configure parameters common for all MLCubes in a particular environments. They can include docker executable, GPU and CPU docker arguments, user SSH and cloud credentials, etc. - Optionally, runners can use parameters defined in platform section of MLCube configuration file. This section usually contains information about such requirements as memory and persistent storage requirements, number of accelerators etc. MLCube standard requires that all runners implement mandatory functionality. All reference runners implement it. Users can develop their own runners to meet their specific requirements, such as security, authentication and authorization policies, and others. Reference MLCube runners \u00b6 Reference runners are: Docker Runner : Runs cubes locally using docker runtime. GCP Runner : Runs cubes in Google cloud. Kubernetes Runner : Runs cubes in Kubernetes. Kubeflow Runner : Runs cubes using Kubeflow. Singularity Runner : Runs cubes using singularity runtime. SSH Runner : Runs cubes on remote hosts. SSH Runner uses other runners, such as Docker or Singularity runners, to run cubes on remote hosts. Runner commands \u00b6 Each runner exposes mandatory and optional functionality through a set of commands. This is similar to, for instance, how Git implements its CLI ( git followed by a specific command such as checkout , pull , push etc.). Mandatory MLCube runner commands are configure and run : configure : Configure MLCube. Exact functionality depends on a runner type, but the goal is to ensure that a cube is ready to run. The following are the examples of what can be done at configure phase: build docker or singularity container, create python virtual environment, allocate and configure virtual machine in the cloud, copy cube to a remote host etc. Once configuration is successfully completed, it is assumed a runner can run that cube. run : Run tasks defined in MLCube. Reference runners recognize three parameters - mlcube, platform and task. mlcube : Path to a cube root directory. In future versions, this can be a URI with a specific protocol. Runners could support various MLCube implementations (excluding reference directory-based) such as docker/singularity containers, GitHub repositories, compressed archives and others. platform : Name of a platform. By default, runners create standard platform configurations in MLCube system settings file with predefined names. Users can change those names and use them on a command line. For instance, they can have different names for an 8-way GPU server and a simple CPU-based server for SSH runner. task : Name of a task, or comma-separated list of tasks. Command line interface \u00b6 One way to run a MLCube is to follow the following template supported by all reference runners: mlcube COMMAND --mlcube = MLCUBE_ROOT_DIRECTORY --platform = PLATFORM_NAME --task = TASK_NAME Example command to configure MNIST Docker-based MLCube: mlcube configure --mlcube = examples/mnist --platform = docker Example command to run two tasks implemented by the MNIST Docker-based MLCube: mlcube run --mlcube = examples/mnist --platform = docker --task = download mlcube run --mlcube = examples/mnist --platform = docker --task = train Configuration subsystem \u00b6 Runners are configured using information from three different sources: The base configuration comes from the system settings file. By default, the location of this file is ${HOME}/mlflow.yaml . It is created automatically whenever a user runs mlcube command line tool. The purpose of this file is to provide system-wide configuration for runners that are specific to user and their environment. This is kind of information that should not generally present in MLCube configuration files (next item). It shoud include such information as docker executable (docker, sudo docker, nvidia-docker, podman, etc), docker-specific runtime arguments, user credentials for GCP and remote hosts, information about remote hosts etc. The MLCube configuration file that is available with each MLCube cube. This file contains (as of now) such parameters, as docker and singularity image names, MLCube resource requirements and tasks. This information overrides information from system settings file. Configuration that is provided on a command line. Users are allowed (but not encouraged) to override parameters on the fly when they run MLCube cubes. MLCube System settings file \u00b6 Example of MLCube system settings file ( ${HOME}/mlcube.yaml ) is the following. As it was mentioned above, it is created automatically by searching packages that start with mlcube_ . Such packages must provide get_runner_class function that must return a runner class derived from Runner . # This section maps a runner name to a runner package. This is one way how developers can plug in # their custom runners. Python package, or this type of association, could be one of many ways to # implement runners. runners : docker : # MLCube Docker reference runner pkg : mlcube_docker gcp : # MLCube Google Cloud Platform reference runner pkg : mlcube_gcp k8s : # MLCube Kubernetes reference runner pkg : mlcube_k8s kubeflow : # MLCube KubeFlow reference runner pkg : mlcube_kubeflow singularity : # MLCube Singularity reference runner pkg : mlcube_singularity ssh : # MLCube SSH reference runner pkg : mlcube_ssh # This section defines configurations for the above runners. It is a dictionary mapping platform # name to a runner configuration. These names could be any names. For instance, users can have # two platforms for an SSH runner pointing to two different remote hosts. The platform names are # those passed to mlcube tool using `--platform` command line argument. platforms : # Docker runner configuration. The only parameter that is supposed to be present in MLCube # configuration files is image name (`image`). For other parameters, see Docker Runner # documentation page. docker : runner : docker image : ${docker.image} docker : docker env_args : {} gpu_args : '' cpu_args : '' build_args : {} build_context : . build_file : Dockerfile build_strategy : pull # Google Cloud Platform runner. None of these configuration parameters are supposed to be # present in MLCube configuration files. For other parameters, see GCP Runner documentation # page. gcp : runner : gcp gcp : project_id : '' zone : '' credentials : '' instance : name : '' machine_type : '' disk_size_gb : '' platform : '' # Kubernetes runner. None of these configuration parameters are supposed to be present in # MLCube configuration files. For other parameters, see Kubernetes Runner documentation page. k8s : runner : k8s pvc : ${name} image : ${docker.image} namespace : default # Kubeflow runner. None of these configuration parameters are supposed to be present in # MLCube configuration files. For other parameters, see Kubeflow Runner documentation page. kubeflow : runner : kubeflow image : ${docker.image} pvc : ??? namespace : default pipeline_host : '' # Singularity runner configuration. The only parameter that is supposed to be present in MLCube # configuration files is image name (`image`). For other parameters, see Singularity Runner # documentation page. singularity : runner : singularity image : ${singularity.image} image_dir : ${runtime.workspace}/.image singularity : singularity build_args : --fakeroot build_file : Singularity.recipe # SSH runner. None of these configuration parameters are supposed to be present in # MLCube configuration files. For other parameters, see SSH Runner documentation page. ssh : runner : ssh host : '' platform : '' remote_root : '' interpreter : {} authentication : {} # Dedicated section to define future data `storage` layer. It's work in progress. storage : {} Users can and should update configuration parameters according to their environment. Also, please backup this file regularly. One possibility is to move this file to a location that is regularly snapshoted. When non-standard path is used, users must define a MLCUBE_SYSTEM_SETTINGS environment variable that points to this new location. Users can also duplicate runner sections assigning names accordingly, like it was mentioned above. For instance, users can have two ssh sections one for each different host: platforms : my_dev_server_1 : runner : ssh # Other parameters ... my_dev_server_2 : runner : ssh # Other parameters ... and then mlcube run --mlcube = . --task = MY_TASK --platform = my_dev_server_2 MLCube runtime provides minimal functionality to interact with system settings file: # Print system settings file mlcube config --list # Query a value associated with the particular key mlcube config --get runners mlcube config --get platforms.docker # Create a new fresh platform for this runner mlcube config --create-platform ssh my_dev_server_1 mlcube config --get platforms.my_dev_server_1 # Rename platform mlcube config --rename-platform my_dev_server_1 my_dev_server_2 mlcube config --get platforms.my_dev_server_2 # Remove platform from the system settings file mlcube config --remove-platform my_dev_server_2 # Create a new platform copying configuration of one of existing platforms. mlcube config --copy-platform EXISTING_PLATFORM NEW_PLATFORM # Rename existing runner mlcube config --rename-runner OLD_NAME NEW_NAME # Remove runner mlcube config --remove-runner NAME Removed standard runners (MLCube reference runners) will be recreated when mlcube runs next time.","title":"Runners"},{"location":"runners/#runners","text":"MLCube runners run MLCube cubes on one or multiple platforms. Examples of platforms are Docker and Singularity containers, Kubernetes, remote hosts, virtual machines in the cloud, etc. Every runner has a fixed set of configuration parameters that users can change to configure MLCubes and runners for their environments. Concretely, runners can take information from three different sources: - MLCube configuration files that are located in the root directory of each file-system based MLCube. Parameters in these files configure generic parameters common for all environments, such as for instance, docker image names. - MLCube system settings file that is located (by default) in the user home directory ( ~/mlcube.yaml ). This file is created automatically, and can be used to configure parameters common for all MLCubes in a particular environments. They can include docker executable, GPU and CPU docker arguments, user SSH and cloud credentials, etc. - Optionally, runners can use parameters defined in platform section of MLCube configuration file. This section usually contains information about such requirements as memory and persistent storage requirements, number of accelerators etc. MLCube standard requires that all runners implement mandatory functionality. All reference runners implement it. Users can develop their own runners to meet their specific requirements, such as security, authentication and authorization policies, and others.","title":"Runners"},{"location":"runners/#reference-mlcube-runners","text":"Reference runners are: Docker Runner : Runs cubes locally using docker runtime. GCP Runner : Runs cubes in Google cloud. Kubernetes Runner : Runs cubes in Kubernetes. Kubeflow Runner : Runs cubes using Kubeflow. Singularity Runner : Runs cubes using singularity runtime. SSH Runner : Runs cubes on remote hosts. SSH Runner uses other runners, such as Docker or Singularity runners, to run cubes on remote hosts.","title":"Reference MLCube runners"},{"location":"runners/#runner-commands","text":"Each runner exposes mandatory and optional functionality through a set of commands. This is similar to, for instance, how Git implements its CLI ( git followed by a specific command such as checkout , pull , push etc.). Mandatory MLCube runner commands are configure and run : configure : Configure MLCube. Exact functionality depends on a runner type, but the goal is to ensure that a cube is ready to run. The following are the examples of what can be done at configure phase: build docker or singularity container, create python virtual environment, allocate and configure virtual machine in the cloud, copy cube to a remote host etc. Once configuration is successfully completed, it is assumed a runner can run that cube. run : Run tasks defined in MLCube. Reference runners recognize three parameters - mlcube, platform and task. mlcube : Path to a cube root directory. In future versions, this can be a URI with a specific protocol. Runners could support various MLCube implementations (excluding reference directory-based) such as docker/singularity containers, GitHub repositories, compressed archives and others. platform : Name of a platform. By default, runners create standard platform configurations in MLCube system settings file with predefined names. Users can change those names and use them on a command line. For instance, they can have different names for an 8-way GPU server and a simple CPU-based server for SSH runner. task : Name of a task, or comma-separated list of tasks.","title":"Runner commands"},{"location":"runners/#command-line-interface","text":"One way to run a MLCube is to follow the following template supported by all reference runners: mlcube COMMAND --mlcube = MLCUBE_ROOT_DIRECTORY --platform = PLATFORM_NAME --task = TASK_NAME Example command to configure MNIST Docker-based MLCube: mlcube configure --mlcube = examples/mnist --platform = docker Example command to run two tasks implemented by the MNIST Docker-based MLCube: mlcube run --mlcube = examples/mnist --platform = docker --task = download mlcube run --mlcube = examples/mnist --platform = docker --task = train","title":"Command line interface"},{"location":"runners/#configuration-subsystem","text":"Runners are configured using information from three different sources: The base configuration comes from the system settings file. By default, the location of this file is ${HOME}/mlflow.yaml . It is created automatically whenever a user runs mlcube command line tool. The purpose of this file is to provide system-wide configuration for runners that are specific to user and their environment. This is kind of information that should not generally present in MLCube configuration files (next item). It shoud include such information as docker executable (docker, sudo docker, nvidia-docker, podman, etc), docker-specific runtime arguments, user credentials for GCP and remote hosts, information about remote hosts etc. The MLCube configuration file that is available with each MLCube cube. This file contains (as of now) such parameters, as docker and singularity image names, MLCube resource requirements and tasks. This information overrides information from system settings file. Configuration that is provided on a command line. Users are allowed (but not encouraged) to override parameters on the fly when they run MLCube cubes.","title":"Configuration subsystem"},{"location":"runners/#mlcube-system-settings-file","text":"Example of MLCube system settings file ( ${HOME}/mlcube.yaml ) is the following. As it was mentioned above, it is created automatically by searching packages that start with mlcube_ . Such packages must provide get_runner_class function that must return a runner class derived from Runner . # This section maps a runner name to a runner package. This is one way how developers can plug in # their custom runners. Python package, or this type of association, could be one of many ways to # implement runners. runners : docker : # MLCube Docker reference runner pkg : mlcube_docker gcp : # MLCube Google Cloud Platform reference runner pkg : mlcube_gcp k8s : # MLCube Kubernetes reference runner pkg : mlcube_k8s kubeflow : # MLCube KubeFlow reference runner pkg : mlcube_kubeflow singularity : # MLCube Singularity reference runner pkg : mlcube_singularity ssh : # MLCube SSH reference runner pkg : mlcube_ssh # This section defines configurations for the above runners. It is a dictionary mapping platform # name to a runner configuration. These names could be any names. For instance, users can have # two platforms for an SSH runner pointing to two different remote hosts. The platform names are # those passed to mlcube tool using `--platform` command line argument. platforms : # Docker runner configuration. The only parameter that is supposed to be present in MLCube # configuration files is image name (`image`). For other parameters, see Docker Runner # documentation page. docker : runner : docker image : ${docker.image} docker : docker env_args : {} gpu_args : '' cpu_args : '' build_args : {} build_context : . build_file : Dockerfile build_strategy : pull # Google Cloud Platform runner. None of these configuration parameters are supposed to be # present in MLCube configuration files. For other parameters, see GCP Runner documentation # page. gcp : runner : gcp gcp : project_id : '' zone : '' credentials : '' instance : name : '' machine_type : '' disk_size_gb : '' platform : '' # Kubernetes runner. None of these configuration parameters are supposed to be present in # MLCube configuration files. For other parameters, see Kubernetes Runner documentation page. k8s : runner : k8s pvc : ${name} image : ${docker.image} namespace : default # Kubeflow runner. None of these configuration parameters are supposed to be present in # MLCube configuration files. For other parameters, see Kubeflow Runner documentation page. kubeflow : runner : kubeflow image : ${docker.image} pvc : ??? namespace : default pipeline_host : '' # Singularity runner configuration. The only parameter that is supposed to be present in MLCube # configuration files is image name (`image`). For other parameters, see Singularity Runner # documentation page. singularity : runner : singularity image : ${singularity.image} image_dir : ${runtime.workspace}/.image singularity : singularity build_args : --fakeroot build_file : Singularity.recipe # SSH runner. None of these configuration parameters are supposed to be present in # MLCube configuration files. For other parameters, see SSH Runner documentation page. ssh : runner : ssh host : '' platform : '' remote_root : '' interpreter : {} authentication : {} # Dedicated section to define future data `storage` layer. It's work in progress. storage : {} Users can and should update configuration parameters according to their environment. Also, please backup this file regularly. One possibility is to move this file to a location that is regularly snapshoted. When non-standard path is used, users must define a MLCUBE_SYSTEM_SETTINGS environment variable that points to this new location. Users can also duplicate runner sections assigning names accordingly, like it was mentioned above. For instance, users can have two ssh sections one for each different host: platforms : my_dev_server_1 : runner : ssh # Other parameters ... my_dev_server_2 : runner : ssh # Other parameters ... and then mlcube run --mlcube = . --task = MY_TASK --platform = my_dev_server_2 MLCube runtime provides minimal functionality to interact with system settings file: # Print system settings file mlcube config --list # Query a value associated with the particular key mlcube config --get runners mlcube config --get platforms.docker # Create a new fresh platform for this runner mlcube config --create-platform ssh my_dev_server_1 mlcube config --get platforms.my_dev_server_1 # Rename platform mlcube config --rename-platform my_dev_server_1 my_dev_server_2 mlcube config --get platforms.my_dev_server_2 # Remove platform from the system settings file mlcube config --remove-platform my_dev_server_2 # Create a new platform copying configuration of one of existing platforms. mlcube config --copy-platform EXISTING_PLATFORM NEW_PLATFORM # Rename existing runner mlcube config --rename-runner OLD_NAME NEW_NAME # Remove runner mlcube config --remove-runner NAME Removed standard runners (MLCube reference runners) will be recreated when mlcube runs next time.","title":"MLCube System settings file"},{"location":"runners/docker-runner/","text":"Docker Runner \u00b6 Docker runner uses docker/nvidia-docker/podman to run MLCube cubes. It supports two mandatory commands - configure and run with standard arguments - mlcube , platform and task . Users can configure docker runner in MLCube configuration file, system setting file, and override parameters on a command line. Configuration parameters \u00b6 MLCube reference docker runner supports the following configuration parameters (with default values): # Docker Image name, for instance \"mlcommons/mnist:0.0.1\" image : ${docker.image} # Docker executable (docker, podman, sudo docker ...). docker : docker # Environmental variables for run command (-e name=value). env_args : {} # Docker run arguments when ${platform.accelerator_count} > 0. gpu_args : '' # Docker run arguments when ${platform.accelerator_count} == 0. cpu_args : '' # Docker build arguments (--build-arg name=value) build_args : {} # Docker build context relative to $MLCUBE_ROOT. Default is $MLCUBE_ROOT. build_context : . # Docker file relative to $MLCUBE_ROOT, default is `$MLCUBE_ROOT/Dockerfile`. build_file : Dockerfile # MLCube configuration strategy # 'pull': never try to build, always pull # 'auto': build if image not found and dockerfile found # 'always': build even if image found build_strategy : pull Configuring MLCubes \u00b6 Docker runner uses build_strategy configuration parameter to decide on build strategy: pull : always try to pull docker image, never attempt to build. auto : use build_context and build_file to decide if Dockerfile exists. If it exists, build the image. always : build docker image always when running MLCube tasks. Docker runner under the hood runs the following command line: ${docker.docker} build ${docker.build_args} -t ${docker.image} -f ${recipe} ${context} where: ${docker.docker} is the docker executable. ${docker.build_args} docker build arguments. ${docker.image} is the docker image name. ${recipe} is the ${docker.build_file} relative to context ${context} is the ${docker.build_context} relative to MLCube root directory. Users do not need to run the configure command explicitly, docker runner uses the following logic to decide what to do before running any task. If strategy is always , build the docker image. Else, if docker image exists, do nothing, else build or pull depending on what strategy is and if Dockerfile exists in MLCube directory. Running MLCubes \u00b6 Docker runner runs the following command: ${docker.docker} run {run_args} ${docker.env_args} {volumes} ${docker.image} {task_args} where: ${docker.docker} is the docker executable. {run_args} are either ${docker.cpu_args} or ${docker.gpu_args} depending on ${platform.num_accelerators} value. ${docker.env_args} are the docker environmental variables. {volumes} are the mount points that the runner automatically constructs based upon the task input/output specifications. ${docker.image} is the docker image name. {task_args} is the task command line arguments, constructed automatically by the runner.","title":"Docker Runner"},{"location":"runners/docker-runner/#docker-runner","text":"Docker runner uses docker/nvidia-docker/podman to run MLCube cubes. It supports two mandatory commands - configure and run with standard arguments - mlcube , platform and task . Users can configure docker runner in MLCube configuration file, system setting file, and override parameters on a command line.","title":"Docker Runner"},{"location":"runners/docker-runner/#configuration-parameters","text":"MLCube reference docker runner supports the following configuration parameters (with default values): # Docker Image name, for instance \"mlcommons/mnist:0.0.1\" image : ${docker.image} # Docker executable (docker, podman, sudo docker ...). docker : docker # Environmental variables for run command (-e name=value). env_args : {} # Docker run arguments when ${platform.accelerator_count} > 0. gpu_args : '' # Docker run arguments when ${platform.accelerator_count} == 0. cpu_args : '' # Docker build arguments (--build-arg name=value) build_args : {} # Docker build context relative to $MLCUBE_ROOT. Default is $MLCUBE_ROOT. build_context : . # Docker file relative to $MLCUBE_ROOT, default is `$MLCUBE_ROOT/Dockerfile`. build_file : Dockerfile # MLCube configuration strategy # 'pull': never try to build, always pull # 'auto': build if image not found and dockerfile found # 'always': build even if image found build_strategy : pull","title":"Configuration parameters"},{"location":"runners/docker-runner/#configuring-mlcubes","text":"Docker runner uses build_strategy configuration parameter to decide on build strategy: pull : always try to pull docker image, never attempt to build. auto : use build_context and build_file to decide if Dockerfile exists. If it exists, build the image. always : build docker image always when running MLCube tasks. Docker runner under the hood runs the following command line: ${docker.docker} build ${docker.build_args} -t ${docker.image} -f ${recipe} ${context} where: ${docker.docker} is the docker executable. ${docker.build_args} docker build arguments. ${docker.image} is the docker image name. ${recipe} is the ${docker.build_file} relative to context ${context} is the ${docker.build_context} relative to MLCube root directory. Users do not need to run the configure command explicitly, docker runner uses the following logic to decide what to do before running any task. If strategy is always , build the docker image. Else, if docker image exists, do nothing, else build or pull depending on what strategy is and if Dockerfile exists in MLCube directory.","title":"Configuring MLCubes"},{"location":"runners/docker-runner/#running-mlcubes","text":"Docker runner runs the following command: ${docker.docker} run {run_args} ${docker.env_args} {volumes} ${docker.image} {task_args} where: ${docker.docker} is the docker executable. {run_args} are either ${docker.cpu_args} or ${docker.gpu_args} depending on ${platform.num_accelerators} value. ${docker.env_args} are the docker environmental variables. {volumes} are the mount points that the runner automatically constructs based upon the task input/output specifications. ${docker.image} is the docker image name. {task_args} is the task command line arguments, constructed automatically by the runner.","title":"Running MLCubes"},{"location":"runners/gcp-runner/","text":"Google Compute Platform (GCP) Runner \u00b6 DISCLAIMER MLCube is under active development. Allocating and using instances in clouds are associated with costs. Users of GCP runners should be aware about it, especially, taking into account capability of GCP runners to automatically create and start remote instances. GCP RUNNERS in current implementation DO NOT stop/destroy remote instances. Users are encouraged to visit web consoles to identify what virtual instances exist and run. GCP runner can update users' ${HOME}/.ssh/config configuration files. GCP runner is a frontend runner for running MLCubes in Google cloud. It is called a frontend runner because it does not actually run cubes, but ensures that a remote instance is up and running, and then uses other runners to actually run MLCubes. The following chain of runners is supported and has been tested: 1. A user interacts with GCP runners. These runners are responsible for creating remote instances (if they do not exist), start them, install required software stack (such as docker or singularity). 2. Once a remote instance is up and running, GCP runners delegates further execution to other runners, such as SSH runners . SSH runners are responsible for delivering MLCubes to remote instances. SSH runners then delegate the actual execution of cubes on those remote instances to such runners as docker runner or singularity runner . The described scenario assumes the presence of the following platform configuration files: GCP, SSH and one of Docker or Singularity. As MLCube project evolves, other paths may become possible to run cubes in clouds such as GCP. Pre-requisites \u00b6 To use GCP runners, users need to have a GCP account. The following account details must be known and available in advance: 1. Project ID. 2. Zone. 3. Service account JSON file . 4. Users should configure their GCP accounts so that ever new virtual instance is automatically deployed with user public key making it available through SSH access automatically. Creating remote instances \u00b6 Remote instances for running MLCubes can be created manually or automatically. 1. To create a virtual instance manually, go to GCP console, select Compute Engine and then VM instances . Write down an instance name. 2. To create a virtual instance automatically, a GCP platform file needs be configured. A limited functionality is supported. Basically, users can only specify machine type and disk size . Ubuntu 18.04 OS will be used as a base image. Configuration parameters \u00b6 gcp : # These are your project ID and zone names. project_id : '' zone : '' # As described above, ensure you have service account activated and download your JSON key file. credentials : file : '${HOME}/.gcp/service_account_key_file.json' scopes : [ 'https://www.googleapis.com/auth/cloud-platform' ] # Instance parameters. # If existing remote instance is used, only `name` field is used. Other fields are not taken # into account. If users want GCP runners to automatically create remote instances, all three # fields must present. Instance name is arbitrary name for this instance. Machine type must be # the valid GCP machine type. Ubuntu 18.04 is used as a base OS. instance : name : '' machine_type : '' disk_size_gb : '' # As described above, primary role of GCP runners is to ensure a remote instance exists before # delegating the actual `MLCube run` functionality to other runners. Currently, the only available # option is an SSH runner (that assumes remote instances are available vis SSH i.e. they have # public IPs). The `platform` field below specifies what runner the GCP runner should be using # once GCP virtual instance has been created. An SSH runner needs to be configured separately # (see sections below for some recommendations and best practices). platform : '' Configuring MLCubes \u00b6 GCP runners execute the following steps during the configuration phase: 1. Check that SSH access has been configured. A runner loads users ${HOME}/.ssh/config file and verifies it contains a section for the remote instance there (specified by the name). The configuration section must define User and IdentityFile . 2. GCP runner connects to GCP using provided project ID, zone name and credentials (file name and scopes). 3. GCP runner checks if a remote instance exists with the provided name. If it does not exist, it creates it using three parameters described above - instance name, machine type and disk size. 4. If a remote instance is not running, GCP runner starts it. 5. GCP runner retrieves a remote instance's metadata that includes public IP address. If public IP address does not match HostName in ssh configuration file, GCP RUNNER UPDATES USER SSH CONFIG FILE . 6. Currently, GCP runner automatically installs such packages, as docker , python3 and virtualenv . 7. GCP runner calls SSH runner to continue configuring remote instance in a MLCube-specific way. Running MLCubes \u00b6 GCP runner does not implement any specific logic and redirects its functionality to an SSH runner. Recommendations \u00b6 One remote instance can be used to run different MLCubes. Names of remote instances can reflect their type, for instance, gcp_free_micro_instance , gcp_4_cpu_instance , gcp_1_gpu_instance , gcp_8_gpu_instance etc. Following the above guidelines, these instances must be configured with key-based SSH access (GCP and SSH runners depend on this). Each remote instance must have a section in the {HOME}/.ssh/config that should look like: Host mlcube-gcp-instance-n1s4 HostName {{PUBLIC_IP_ADDRESS}} IdentityFile ~/.ssh/gcp_rsa User {{GCP_USER_LOGIN_NAME}} GCP runner will update the HostName value if actual IP address differs from existing one. Other fields are never updated by GCP runners. Section like this one is sufficient to partially configure GCP and fully configure SSH runners. After every GCP run, decide if a remote instance needs to be stopped/destroyed. If so, go to web console.","title":"GCP Runner"},{"location":"runners/gcp-runner/#google-compute-platform-gcp-runner","text":"DISCLAIMER MLCube is under active development. Allocating and using instances in clouds are associated with costs. Users of GCP runners should be aware about it, especially, taking into account capability of GCP runners to automatically create and start remote instances. GCP RUNNERS in current implementation DO NOT stop/destroy remote instances. Users are encouraged to visit web consoles to identify what virtual instances exist and run. GCP runner can update users' ${HOME}/.ssh/config configuration files. GCP runner is a frontend runner for running MLCubes in Google cloud. It is called a frontend runner because it does not actually run cubes, but ensures that a remote instance is up and running, and then uses other runners to actually run MLCubes. The following chain of runners is supported and has been tested: 1. A user interacts with GCP runners. These runners are responsible for creating remote instances (if they do not exist), start them, install required software stack (such as docker or singularity). 2. Once a remote instance is up and running, GCP runners delegates further execution to other runners, such as SSH runners . SSH runners are responsible for delivering MLCubes to remote instances. SSH runners then delegate the actual execution of cubes on those remote instances to such runners as docker runner or singularity runner . The described scenario assumes the presence of the following platform configuration files: GCP, SSH and one of Docker or Singularity. As MLCube project evolves, other paths may become possible to run cubes in clouds such as GCP.","title":"Google Compute Platform (GCP) Runner"},{"location":"runners/gcp-runner/#pre-requisites","text":"To use GCP runners, users need to have a GCP account. The following account details must be known and available in advance: 1. Project ID. 2. Zone. 3. Service account JSON file . 4. Users should configure their GCP accounts so that ever new virtual instance is automatically deployed with user public key making it available through SSH access automatically.","title":"Pre-requisites"},{"location":"runners/gcp-runner/#creating-remote-instances","text":"Remote instances for running MLCubes can be created manually or automatically. 1. To create a virtual instance manually, go to GCP console, select Compute Engine and then VM instances . Write down an instance name. 2. To create a virtual instance automatically, a GCP platform file needs be configured. A limited functionality is supported. Basically, users can only specify machine type and disk size . Ubuntu 18.04 OS will be used as a base image.","title":"Creating remote instances"},{"location":"runners/gcp-runner/#configuration-parameters","text":"gcp : # These are your project ID and zone names. project_id : '' zone : '' # As described above, ensure you have service account activated and download your JSON key file. credentials : file : '${HOME}/.gcp/service_account_key_file.json' scopes : [ 'https://www.googleapis.com/auth/cloud-platform' ] # Instance parameters. # If existing remote instance is used, only `name` field is used. Other fields are not taken # into account. If users want GCP runners to automatically create remote instances, all three # fields must present. Instance name is arbitrary name for this instance. Machine type must be # the valid GCP machine type. Ubuntu 18.04 is used as a base OS. instance : name : '' machine_type : '' disk_size_gb : '' # As described above, primary role of GCP runners is to ensure a remote instance exists before # delegating the actual `MLCube run` functionality to other runners. Currently, the only available # option is an SSH runner (that assumes remote instances are available vis SSH i.e. they have # public IPs). The `platform` field below specifies what runner the GCP runner should be using # once GCP virtual instance has been created. An SSH runner needs to be configured separately # (see sections below for some recommendations and best practices). platform : ''","title":"Configuration parameters"},{"location":"runners/gcp-runner/#configuring-mlcubes","text":"GCP runners execute the following steps during the configuration phase: 1. Check that SSH access has been configured. A runner loads users ${HOME}/.ssh/config file and verifies it contains a section for the remote instance there (specified by the name). The configuration section must define User and IdentityFile . 2. GCP runner connects to GCP using provided project ID, zone name and credentials (file name and scopes). 3. GCP runner checks if a remote instance exists with the provided name. If it does not exist, it creates it using three parameters described above - instance name, machine type and disk size. 4. If a remote instance is not running, GCP runner starts it. 5. GCP runner retrieves a remote instance's metadata that includes public IP address. If public IP address does not match HostName in ssh configuration file, GCP RUNNER UPDATES USER SSH CONFIG FILE . 6. Currently, GCP runner automatically installs such packages, as docker , python3 and virtualenv . 7. GCP runner calls SSH runner to continue configuring remote instance in a MLCube-specific way.","title":"Configuring MLCubes"},{"location":"runners/gcp-runner/#running-mlcubes","text":"GCP runner does not implement any specific logic and redirects its functionality to an SSH runner.","title":"Running MLCubes"},{"location":"runners/gcp-runner/#recommendations","text":"One remote instance can be used to run different MLCubes. Names of remote instances can reflect their type, for instance, gcp_free_micro_instance , gcp_4_cpu_instance , gcp_1_gpu_instance , gcp_8_gpu_instance etc. Following the above guidelines, these instances must be configured with key-based SSH access (GCP and SSH runners depend on this). Each remote instance must have a section in the {HOME}/.ssh/config that should look like: Host mlcube-gcp-instance-n1s4 HostName {{PUBLIC_IP_ADDRESS}} IdentityFile ~/.ssh/gcp_rsa User {{GCP_USER_LOGIN_NAME}} GCP runner will update the HostName value if actual IP address differs from existing one. Other fields are never updated by GCP runners. Section like this one is sufficient to partially configure GCP and fully configure SSH runners. After every GCP run, decide if a remote instance needs to be stopped/destroyed. If so, go to web console.","title":"Recommendations"},{"location":"runners/kubeflow/","text":"Kubeflow Runner \u00b6 Kubeflow supports two mandatory commands - configure and run with standard arguments - mlcube , platform and task . Users can configure SSH runner in system setting file, and override parameters on a command line. The configure command is not required, and does nothing when invoked. Configuration parameters \u00b6 # Use image name from docker configuration section image : ${docker.image} # PVC must point to the active MLCube workspace now. pvc : '???' # eg: set http://127.0.0.1:8000/pipeline when port forwarded svc/ml-pipeline-ui to port 8000 pipeline_host : '' Configuring MLCubes \u00b6 This runner does not need configure step. Running MLCubes \u00b6 To be done.","title":"Kubeflow Runner"},{"location":"runners/kubeflow/#kubeflow-runner","text":"Kubeflow supports two mandatory commands - configure and run with standard arguments - mlcube , platform and task . Users can configure SSH runner in system setting file, and override parameters on a command line. The configure command is not required, and does nothing when invoked.","title":"Kubeflow Runner"},{"location":"runners/kubeflow/#configuration-parameters","text":"# Use image name from docker configuration section image : ${docker.image} # PVC must point to the active MLCube workspace now. pvc : '???' # eg: set http://127.0.0.1:8000/pipeline when port forwarded svc/ml-pipeline-ui to port 8000 pipeline_host : ''","title":"Configuration parameters"},{"location":"runners/kubeflow/#configuring-mlcubes","text":"This runner does not need configure step.","title":"Configuring MLCubes"},{"location":"runners/kubeflow/#running-mlcubes","text":"To be done.","title":"Running MLCubes"},{"location":"runners/kubernetes/","text":"Kubernetes Runner \u00b6 The Kubernetes Runner runs a MLCube on a Kubernetes cluster. Why Kubernetes? \u00b6 One of the key goals of the MLCube project is to enable portability of ML models. Kubernetes offers a good set of abstractions to enable model training to be portable across different compute platforms. Design \u00b6 Kubernetes Runner Proposal Doc The Kubernetes runner takes in a kubernetes specific task file in the run directory and re-uses the Docker runner platform config and prepares a Kubernetes Job manifest. The runner then creates the job on the Kubernetes cluster. Configuration parameters \u00b6 Currently, users must create persistent volume claim (PVC) that points to an actual MLCube workspace directory. # By default, PVC name equals to the name of this MLCube (mnist, matmul, ...). pvc : ${name} # Use image name from docker configuration section. image : ${docker.image} The Kubernetes runner constructs the following Kubernetes Job manifest. apiVersion : batch/v1 kind : Job metadata : namespace : default generateName : mlcube-mnist- spec : template : spec : containers : - name : mlcube-container image : mlcommons/mlcube:mnist args : - --data_dir=/mnt/mlcube/mlcube-input/workspace/data - --model_dir=/mnt/mlcube/mlcube-output/workspace/model volumeMounts : - name : mlcube-input mountPath : /mnt/mlcube/mlcube-input - name : mlcube-output mountPath : /mnt/mlcube/mlcube-output volumes : - name : mlcube-input persistentVolumeClaim : claimName : mlcube-input - name : mlcube-output persistentVolumeClaim : claimName : mlcube-output restartPolicy : Never backoffLimit : 4 Configuring MLCubes \u00b6 This runner does not need configure step. Running MLCubes \u00b6 Algorithm is following: Load Kubernetes configuration. Create job manifest (see above). Create job and wait for completion.","title":"Kubernetes Runner"},{"location":"runners/kubernetes/#kubernetes-runner","text":"The Kubernetes Runner runs a MLCube on a Kubernetes cluster.","title":"Kubernetes Runner"},{"location":"runners/kubernetes/#why-kubernetes","text":"One of the key goals of the MLCube project is to enable portability of ML models. Kubernetes offers a good set of abstractions to enable model training to be portable across different compute platforms.","title":"Why Kubernetes?"},{"location":"runners/kubernetes/#design","text":"Kubernetes Runner Proposal Doc The Kubernetes runner takes in a kubernetes specific task file in the run directory and re-uses the Docker runner platform config and prepares a Kubernetes Job manifest. The runner then creates the job on the Kubernetes cluster.","title":"Design"},{"location":"runners/kubernetes/#configuration-parameters","text":"Currently, users must create persistent volume claim (PVC) that points to an actual MLCube workspace directory. # By default, PVC name equals to the name of this MLCube (mnist, matmul, ...). pvc : ${name} # Use image name from docker configuration section. image : ${docker.image} The Kubernetes runner constructs the following Kubernetes Job manifest. apiVersion : batch/v1 kind : Job metadata : namespace : default generateName : mlcube-mnist- spec : template : spec : containers : - name : mlcube-container image : mlcommons/mlcube:mnist args : - --data_dir=/mnt/mlcube/mlcube-input/workspace/data - --model_dir=/mnt/mlcube/mlcube-output/workspace/model volumeMounts : - name : mlcube-input mountPath : /mnt/mlcube/mlcube-input - name : mlcube-output mountPath : /mnt/mlcube/mlcube-output volumes : - name : mlcube-input persistentVolumeClaim : claimName : mlcube-input - name : mlcube-output persistentVolumeClaim : claimName : mlcube-output restartPolicy : Never backoffLimit : 4","title":"Configuration parameters"},{"location":"runners/kubernetes/#configuring-mlcubes","text":"This runner does not need configure step.","title":"Configuring MLCubes"},{"location":"runners/kubernetes/#running-mlcubes","text":"Algorithm is following: Load Kubernetes configuration. Create job manifest (see above). Create job and wait for completion.","title":"Running MLCubes"},{"location":"runners/singularity-runner/","text":"Singularity Runner \u00b6 Singularity runner uses singularity to run MLCube cubes. It supports two mandatory commands - configure and run with standard arguments - mlcube , platform and task . Users can configure Singularity runner in MLCube configuration file, system setting file, and override parameters on a command line. Configuration parameters \u00b6 MLCube reference singularity runner supports the following configuration parameters (with default values): # Name of a singularity image, for instance \"mnist-0.0.1.simg\". image : ${singularity.image} # Path where to build the image. By default, it is `.image` inside workspace directory. image_dir : ${runtime.workspace}/.image # Singularity executable singularity : singularity # Build arguments build_args : --fakeroot # Singularity recipe file relative to workspace. build_file : Singularity.recipe Configuring MLCubes \u00b6 Users do not need to run the configure command manually, singularity docker runs this whenever image is not found. Singularity runner under the hood runs the following command line: cd {recipe_path} && ${singularity} build ${build_args} {image_uri} ${build_file} where: {recipe_path} is the MLCube root directory. ${singularity} is the singularity executable. ${build_args} is the singularity build arguments. {image_uri} is the full image path ( ${image_dir}/${image} ). ${build_file} is the singularity build file. Running MLCubes \u00b6 Singularity runner runs the following command: ${singularity} run {volumes} {image_path} {task_args} where: ${singularity} is the singularity executable. {volumes} are the mount points that the runner automatically constructs based upon the task input/output specifications. {image_path} is the path to Singularity image ( {image_dir}/{image} ). {task_args} is the task command line arguments, constructed automatically by the runner.","title":"Singularity Runner"},{"location":"runners/singularity-runner/#singularity-runner","text":"Singularity runner uses singularity to run MLCube cubes. It supports two mandatory commands - configure and run with standard arguments - mlcube , platform and task . Users can configure Singularity runner in MLCube configuration file, system setting file, and override parameters on a command line.","title":"Singularity Runner"},{"location":"runners/singularity-runner/#configuration-parameters","text":"MLCube reference singularity runner supports the following configuration parameters (with default values): # Name of a singularity image, for instance \"mnist-0.0.1.simg\". image : ${singularity.image} # Path where to build the image. By default, it is `.image` inside workspace directory. image_dir : ${runtime.workspace}/.image # Singularity executable singularity : singularity # Build arguments build_args : --fakeroot # Singularity recipe file relative to workspace. build_file : Singularity.recipe","title":"Configuration parameters"},{"location":"runners/singularity-runner/#configuring-mlcubes","text":"Users do not need to run the configure command manually, singularity docker runs this whenever image is not found. Singularity runner under the hood runs the following command line: cd {recipe_path} && ${singularity} build ${build_args} {image_uri} ${build_file} where: {recipe_path} is the MLCube root directory. ${singularity} is the singularity executable. ${build_args} is the singularity build arguments. {image_uri} is the full image path ( ${image_dir}/${image} ). ${build_file} is the singularity build file.","title":"Configuring MLCubes"},{"location":"runners/singularity-runner/#running-mlcubes","text":"Singularity runner runs the following command: ${singularity} run {volumes} {image_path} {task_args} where: ${singularity} is the singularity executable. {volumes} are the mount points that the runner automatically constructs based upon the task input/output specifications. {image_path} is the path to Singularity image ( {image_dir}/{image} ). {task_args} is the task command line arguments, constructed automatically by the runner.","title":"Running MLCubes"},{"location":"runners/ssh-runner/","text":"SSH Runner \u00b6 SSH runner uses other runners to run MLCube cubes on remote hosts. It uses ssh and rsync internally. It supports two mandatory commands - configure and run with standard arguments - mlcube , platform and task . Users can configure SSH runner in system setting file, and override parameters on a command line. Work in progress. Some functionality described below may not be available. Configuration parameters \u00b6 # Remote host name or IP address host : '' # Platform (runner) to use on remote host platform : '' # Root path for MLCubes on remote host remote_root : '' # Remote python interpreter. It's a dictionary. # - Must contain: # - `type`: interpreter type (system, virtualenv) # - When type is system (system-wide interpreter), additional parameters must be: # - `python`: python executable, maybe full path or just `python`. # - `requirements`: is a whitespace-separated list of python dependencies. # - When type is virtualenv (python environment created with virtualenv tool), # additional parameters must be: # - `python`: python executable # - `requirements`: is a whitespace-separated list of python dependencies. # - `location`: path where virtual environment must be created. # - `name`: name of the virtual environment. interpreter : {} # Authentication on remote host. It's a dictionary that contain the following fields: # - `identify_file`: if present, will be used as part of the connection # string ('-i {identity_file}') # - `user`: username for the remote host, will be used as '{user}@{host}' authentication : {} SSH runner uses IP or name of a remote host ( host ) and ssh tool to log in and execute shell commands on remote hosts. If passwordless login is not configured, SSH runner asks for password many times during configure and run phases. Configuring MLCubes \u00b6 This runner must be configured by users explicitly: mlcube configure --mlcube=. --platform=ssh During the configure phase, the following steps are performed. Based upon configuration, SSH runner creates and/or configures python on a remote host using ssh . This includes execution of such commands as virtualenv -p ... and/or source ... && pip install ... on a remote host. SSH runner copies mlcube directory to a remote host. SSH runner runs another runner specified in a platform configuration file on a remote host to configure it. Running MLCubes \u00b6 During the run phase, the SSH runner performs the following steps: It uses ssh to run standard run command on a remote host. It uses rsync to synchronize back the content of the {MLCUBE_ROOT}/workspace directory.","title":"SSH Runner"},{"location":"runners/ssh-runner/#ssh-runner","text":"SSH runner uses other runners to run MLCube cubes on remote hosts. It uses ssh and rsync internally. It supports two mandatory commands - configure and run with standard arguments - mlcube , platform and task . Users can configure SSH runner in system setting file, and override parameters on a command line. Work in progress. Some functionality described below may not be available.","title":"SSH Runner"},{"location":"runners/ssh-runner/#configuration-parameters","text":"# Remote host name or IP address host : '' # Platform (runner) to use on remote host platform : '' # Root path for MLCubes on remote host remote_root : '' # Remote python interpreter. It's a dictionary. # - Must contain: # - `type`: interpreter type (system, virtualenv) # - When type is system (system-wide interpreter), additional parameters must be: # - `python`: python executable, maybe full path or just `python`. # - `requirements`: is a whitespace-separated list of python dependencies. # - When type is virtualenv (python environment created with virtualenv tool), # additional parameters must be: # - `python`: python executable # - `requirements`: is a whitespace-separated list of python dependencies. # - `location`: path where virtual environment must be created. # - `name`: name of the virtual environment. interpreter : {} # Authentication on remote host. It's a dictionary that contain the following fields: # - `identify_file`: if present, will be used as part of the connection # string ('-i {identity_file}') # - `user`: username for the remote host, will be used as '{user}@{host}' authentication : {} SSH runner uses IP or name of a remote host ( host ) and ssh tool to log in and execute shell commands on remote hosts. If passwordless login is not configured, SSH runner asks for password many times during configure and run phases.","title":"Configuration parameters"},{"location":"runners/ssh-runner/#configuring-mlcubes","text":"This runner must be configured by users explicitly: mlcube configure --mlcube=. --platform=ssh During the configure phase, the following steps are performed. Based upon configuration, SSH runner creates and/or configures python on a remote host using ssh . This includes execution of such commands as virtualenv -p ... and/or source ... && pip install ... on a remote host. SSH runner copies mlcube directory to a remote host. SSH runner runs another runner specified in a platform configuration file on a remote host to configure it.","title":"Configuring MLCubes"},{"location":"runners/ssh-runner/#running-mlcubes","text":"During the run phase, the SSH runner performs the following steps: It uses ssh to run standard run command on a remote host. It uses rsync to synchronize back the content of the {MLCUBE_ROOT}/workspace directory.","title":"Running MLCubes"},{"location":"tutorials/create-mlcube/","text":"Tutorial: Create an MLCube \u00b6 Interested in getting started with MLCube? Follow the instructions in this tutorial. Step 1: Setup \u00b6 Get MLCube, MLCube examples and MLCube Templates, and CREATE a Python environment. # You can clone the mlcube examples and templates from GtiHub git clone https://github.com/mlcommons/mlcube_examples # Create a python environment virtualenv -p python3 ./env && source ./env/bin/activate # Install mlcube, mlcube-docker and cookiecutter pip install mlcube mlcube-docker cookiecutter Step 2: Configure MLCube using the mlcube_cookiecutter \u00b6 Let's use the matmul example, that we downloaded in the previous step, to illustrate how to make an MLCube. Matmul is a simple matrix multiply example written in Python with TensorFlow. When you create an MLCube for your own model you will use your own code, data and dockerfile. cd mlcube_examples # rename matmul reference implementation from matmul to matmul_reference mv ./matmul ./matmul_reference # create a mlcube directory using mlcube template(note: do not use quotes in your input to # cookiecutter): # mlcube_name = matmul # mlcube_description = Matrix multiplication example # author_name = MLPerf Best Practices Working Group # author_email = first.second@corp.com # author_org = corp cookiecutter https://github.com/mlcommons/mlcube_cookiecutter.git # copy the matmul.py,Dockerfile and requirements.txt to your mlcube_matmul/build directory cp matmul_reference/matmul.py matmul/ cp matmul_reference/Dockerfile matmul/ cp matmul_reference/requirements.txt matmul/ # copy input file for matmul to workspace directory cp -R matmul_reference/workspace matmul Edit the template files Start by looking at the mlcube.yaml file that has been generated by cookiecutter. cd ./matmul Cookiecutter has modified the lines shown in bold in the mlcube.yaml file shown here: # This YAML file marks a directory to be an MLCube directory. When running MLCubes with runners, # MLCube path is specified using `--mlcube` runner command line argument. The most important # parameters that are defined here are (1) name, (2) author and (3) list of MLCube tasks. # MLCube name (string). Replace it with your MLCube name (e.g. \"MNIST\"). name: matmul # MLCube description (string). Replace it with your MLCube name # (e.g. \"MLCommons MNIST MLCube example\"). description: Matrix multiplication example # List of authors. Cookiecutter sets the first author. authors: - name: MLPerf Best Practices Working Group email: first.second@corp.com org: corp # This dictionary can contain information about SW/HW requirements platform: {} # accelerator_count: 0 # accelerator_maker: NVIDIA # accelerator_model: A100-80GB # host_memory_gb: 40 # need_internet_access: True # host_disk_space_gb: 100 # This cookiecutter creates a docker-based MLCube. docker: image: mlcommons/ matmul :0.0.1 # List of MLCube tasks supported by this MLCube. tasks: matmul : parameters: inputs: {parameters_file: parameters_file.yaml} outputs: {output_file: {type: file, default: output.txt}} Our input file shapes.yaml that we have copied previously into the mlcube workspace contains input parameters to set matrix dimensions. We need to remove the automatically generated parameters file. rm workspace/parameters_file.yaml Now we will edit file mlcube.yaml. The lines you need to edit are shown in bold shown here: # This YAML file marks a directory to be an MLCube directory. When running MLCubes with runners, # MLCube path is specified using `--mlcube` runner command line argument. The most important # parameters that are defined here are (1) name, (2) author and (3) list of MLCube tasks. # MLCube name (string). Replace it with your MLCube name (e.g. \"MNIST\"). name: matmul # MLCube description (string). Replace it with your MLCube name # (e.g. \"MLCommons MNIST MLCube example\"). description: Matrix multiplication example # List of authors. Cookiecutter sets the first author. authors: - name: MLPerf Best Practices Working Group email: first.second@corp.com org: corp # This dictionary can contain information about SW/HW requirements platform: {} # accelerator_count: 0 # accelerator_maker: NVIDIA # accelerator_model: A100-80GB # host_memory_gb: 40 # need_internet_access: True # host_disk_space_gb: 100 # This cookiecutter creates a docker-based MLCube. docker: image: mlcommons/matmul:v1.0 # List of MLCube tasks supported by this MLCube. tasks: matmul: parameters: inputs: {parameters_file: shapes.yaml } outputs: {output_file: {type: file, default: matmul_output.txt }} Step 3: Build Docker container Image \u00b6 mlcube configure --mlcube = . --platform = docker -Prunner.build_strategy = auto Step 4: Test your MLCube \u00b6 mlcube run --mlcube = . --platform = docker --task = matmul ls ./workspace cat ./workspace/matmul_output.txt","title":"How to Create an MLCube"},{"location":"tutorials/create-mlcube/#tutorial-create-an-mlcube","text":"Interested in getting started with MLCube? Follow the instructions in this tutorial.","title":"Tutorial: Create an MLCube"},{"location":"tutorials/create-mlcube/#step-1-setup","text":"Get MLCube, MLCube examples and MLCube Templates, and CREATE a Python environment. # You can clone the mlcube examples and templates from GtiHub git clone https://github.com/mlcommons/mlcube_examples # Create a python environment virtualenv -p python3 ./env && source ./env/bin/activate # Install mlcube, mlcube-docker and cookiecutter pip install mlcube mlcube-docker cookiecutter","title":"Step 1: Setup"},{"location":"tutorials/create-mlcube/#step-2-configure-mlcube-using-the-mlcube_cookiecutter","text":"Let's use the matmul example, that we downloaded in the previous step, to illustrate how to make an MLCube. Matmul is a simple matrix multiply example written in Python with TensorFlow. When you create an MLCube for your own model you will use your own code, data and dockerfile. cd mlcube_examples # rename matmul reference implementation from matmul to matmul_reference mv ./matmul ./matmul_reference # create a mlcube directory using mlcube template(note: do not use quotes in your input to # cookiecutter): # mlcube_name = matmul # mlcube_description = Matrix multiplication example # author_name = MLPerf Best Practices Working Group # author_email = first.second@corp.com # author_org = corp cookiecutter https://github.com/mlcommons/mlcube_cookiecutter.git # copy the matmul.py,Dockerfile and requirements.txt to your mlcube_matmul/build directory cp matmul_reference/matmul.py matmul/ cp matmul_reference/Dockerfile matmul/ cp matmul_reference/requirements.txt matmul/ # copy input file for matmul to workspace directory cp -R matmul_reference/workspace matmul Edit the template files Start by looking at the mlcube.yaml file that has been generated by cookiecutter. cd ./matmul Cookiecutter has modified the lines shown in bold in the mlcube.yaml file shown here: # This YAML file marks a directory to be an MLCube directory. When running MLCubes with runners, # MLCube path is specified using `--mlcube` runner command line argument. The most important # parameters that are defined here are (1) name, (2) author and (3) list of MLCube tasks. # MLCube name (string). Replace it with your MLCube name (e.g. \"MNIST\"). name: matmul # MLCube description (string). Replace it with your MLCube name # (e.g. \"MLCommons MNIST MLCube example\"). description: Matrix multiplication example # List of authors. Cookiecutter sets the first author. authors: - name: MLPerf Best Practices Working Group email: first.second@corp.com org: corp # This dictionary can contain information about SW/HW requirements platform: {} # accelerator_count: 0 # accelerator_maker: NVIDIA # accelerator_model: A100-80GB # host_memory_gb: 40 # need_internet_access: True # host_disk_space_gb: 100 # This cookiecutter creates a docker-based MLCube. docker: image: mlcommons/ matmul :0.0.1 # List of MLCube tasks supported by this MLCube. tasks: matmul : parameters: inputs: {parameters_file: parameters_file.yaml} outputs: {output_file: {type: file, default: output.txt}} Our input file shapes.yaml that we have copied previously into the mlcube workspace contains input parameters to set matrix dimensions. We need to remove the automatically generated parameters file. rm workspace/parameters_file.yaml Now we will edit file mlcube.yaml. The lines you need to edit are shown in bold shown here: # This YAML file marks a directory to be an MLCube directory. When running MLCubes with runners, # MLCube path is specified using `--mlcube` runner command line argument. The most important # parameters that are defined here are (1) name, (2) author and (3) list of MLCube tasks. # MLCube name (string). Replace it with your MLCube name (e.g. \"MNIST\"). name: matmul # MLCube description (string). Replace it with your MLCube name # (e.g. \"MLCommons MNIST MLCube example\"). description: Matrix multiplication example # List of authors. Cookiecutter sets the first author. authors: - name: MLPerf Best Practices Working Group email: first.second@corp.com org: corp # This dictionary can contain information about SW/HW requirements platform: {} # accelerator_count: 0 # accelerator_maker: NVIDIA # accelerator_model: A100-80GB # host_memory_gb: 40 # need_internet_access: True # host_disk_space_gb: 100 # This cookiecutter creates a docker-based MLCube. docker: image: mlcommons/matmul:v1.0 # List of MLCube tasks supported by this MLCube. tasks: matmul: parameters: inputs: {parameters_file: shapes.yaml } outputs: {output_file: {type: file, default: matmul_output.txt }}","title":"Step 2: Configure MLCube using the mlcube_cookiecutter"},{"location":"tutorials/create-mlcube/#step-3-build-docker-container-image","text":"mlcube configure --mlcube = . --platform = docker -Prunner.build_strategy = auto","title":"Step 3: Build Docker container Image"},{"location":"tutorials/create-mlcube/#step-4-test-your-mlcube","text":"mlcube run --mlcube = . --platform = docker --task = matmul ls ./workspace cat ./workspace/matmul_output.txt","title":"Step 4: Test your MLCube"}]}