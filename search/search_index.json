{"config":{"lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"MLBox \u00b6 This is the MLBox \ud83d\udce6 Prototype. Get MLBox \u00b6 Direct Download \u00b6 Directly download the project wget -O mlbox-master.zip https://github.com/mlperf/mlbox/archive/master.zip unzip mlbox-master.zip -d mlbox rm -r mlbox-master.zip cd mlbox Git Clone \u00b6 You can clone the MLBox project using Git git clone https://github.com/mlperf/mlbox.git cd mlbox Installing \u00b6 After downloading or cloning, from the root of the project directory you can install: pip install . To uninstall: pip uninstall mlbox Running Locally \u00b6 Toy Implementation \u00b6 To run the toy implementation (aka \"fake model\"): Notice This is not yet fully implemented. This will print a docker command simliar to what will be run. cd mlbox python mlbox_run.py ../examples/fake_model:train/small_batch To override and specify different files: --log_file=/tmp/my_log_file Transformer Implementation \u00b6 To run the transformer implementation: cd mlbox/ python mlbox_local_run.py ../examples/transformer:downloaddata/default python mlbox_local_run.py ../examples/transformer:preprocess/default python mlbox_local_run.py ../examples/transformer:train/default Usage Examples \u00b6 Check out the examples directory for detailed examples. License \u00b6 MLBox is licensed under the Apache License 2.0. See LICENSE for more information. Support \u00b6 Create a GitHub issue","title":"Home"},{"location":"#mlbox","text":"This is the MLBox \ud83d\udce6 Prototype.","title":"MLBox"},{"location":"#get-mlbox","text":"","title":"Get MLBox"},{"location":"#direct-download","text":"Directly download the project wget -O mlbox-master.zip https://github.com/mlperf/mlbox/archive/master.zip unzip mlbox-master.zip -d mlbox rm -r mlbox-master.zip cd mlbox","title":"Direct Download"},{"location":"#git-clone","text":"You can clone the MLBox project using Git git clone https://github.com/mlperf/mlbox.git cd mlbox","title":"Git Clone"},{"location":"#installing","text":"After downloading or cloning, from the root of the project directory you can install: pip install . To uninstall: pip uninstall mlbox","title":"Installing"},{"location":"#running-locally","text":"","title":"Running Locally"},{"location":"#toy-implementation","text":"To run the toy implementation (aka \"fake model\"): Notice This is not yet fully implemented. This will print a docker command simliar to what will be run. cd mlbox python mlbox_run.py ../examples/fake_model:train/small_batch To override and specify different files: --log_file=/tmp/my_log_file","title":"Toy Implementation"},{"location":"#transformer-implementation","text":"To run the transformer implementation: cd mlbox/ python mlbox_local_run.py ../examples/transformer:downloaddata/default python mlbox_local_run.py ../examples/transformer:preprocess/default python mlbox_local_run.py ../examples/transformer:train/default","title":"Transformer Implementation"},{"location":"#usage-examples","text":"Check out the examples directory for detailed examples.","title":"Usage Examples"},{"location":"#license","text":"MLBox is licensed under the Apache License 2.0. See LICENSE for more information.","title":"License"},{"location":"#support","text":"Create a GitHub issue","title":"Support"},{"location":"getting-started/","text":"Getting Started \u00b6","title":"Getting Started"},{"location":"getting-started/#getting-started","text":"","title":"Getting Started"},{"location":"getting-started/hello-world/","text":"Hello World \u00b6 Docker runtime \u00b6 Hello World MLBox is an example of a docker-based MLBox, and docker runtime must be installed in a system. Installation guides for various operating systems can be found here . This example was tested on a system where users are in the docker group and run docker without sudo . To add yourself to a docker group, run the following: sudo groupadd docker # Add the docker group if it doesn't already exist. sudo gpasswd -a ${USER} docker # Add the connected user \"${USER}\" to the docker group. Change the user name to match your preferred user. sudo service docker restart # Restart the Docker daemon. newgrp docker # Either do a\u00c2 newgrp docker\u00c2 or log out/in to activate the changes to groups. Host python environment \u00b6 Hello World is an example of a simple python program distributed as an MLBox. This tutorial covers the case when MLBox library and Hello World MLBox are cloned from the GitHub repository: git clone https://github.com/mlperf/mlbox ./mlbox cd ./mlbox Python >= 3.6 is required together with runners' python dependencies: virtualenv -p python3.8 ./env source ./env/bin/activate pip install typer mlspeclib export PYTHONPATH=$(pwd)/mlcommons_box:$(pwd)/runners/mlbox_singularity_run:$(pwd)/runners/mlbox_docker_run Optionally, setup host environment by providing the correct http_proxy and https_proxy environmental variables. export http_proxy=... export https_proxy=... Configuring MLBox \u00b6 MLBoxes need to be configured before they can run. To do so, users need to run the MLBox runner with configure command providing path to a MLBox root directory and path to a platform configuration file. Hello World MLBox is a docker-based MLBox, so users provide path to a Docker platform configuration file that sets a number of parameters, including docker image name: python -m mlbox_docker_run configure --mlbox=examples/hello_world --platform=examples/hello_world/platform/docker.yaml Docker runner will build a docker image for the Hello World MLBox. Running MLBox \u00b6 In order to run MLBox, users need to provide the path to the root directory of the MLBox, platform configuration file and path to a task definition file. Run the following two commands one at a time: python -m mlbox_docker_run run --mlbox=examples/hello_world --platform=examples/hello_world/platform/docker.yaml --task=examples/hello_world/run/alice/hello.yaml python -m mlbox_docker_run run --mlbox=examples/hello_world --platform=examples/hello_world/platform/docker.yaml --task=examples/hello_world/run/alice/bye.yaml MLBox creates a file examples/hello_world/workspace/chats/chat_with_alice.txt that contains the following: [2020-09-03 09:13:14.236945] Hi, Alice! Nice to meet you. [2020-09-03 09:13:20.749831] Bye, Alice! It was great talking to you. Modifying MLBox \u00b6 Adding new user \u00b6 Create a new file examples/hello_world/workspace/names/donald.txt with the following content: Donald . Create a new file examples/hello_world/run/donald/hello.yaml with the following content: schema_type : mlbox_invoke schema_version : 1.0.0 task_name : hello input_binding : name : $WORKSPACE/names/donald.txt output_binding : chat : $WORKSPACE/chats/chat_with_donald.txt Create a new file examples/hello_world/run/donald/bye.yaml with the following content: schema_type : mlbox_invoke schema_version : 1.0.0 task_name : bye input_binding : name : $WORKSPACE/names/donald.txt output_binding : chat : $WORKSPACE/chats/chat_with_donald.txt Run the following two commands one at a time: python -m mlbox_docker_run run --mlbox=examples/hello_world --platform=examples/hello_world/platform/docker.yaml --task=examples/hello_world/run/donald/hello.yaml python -m mlbox_docker_run run --mlbox=examples/hello_world --platform=examples/hello_world/platform/docker.yaml --task=examples/hello_world/run/donald/bye.yaml MLBox creates a file examples/hello_world/workspace/chats/chat_with_donald.txt that contains the following: [2020-09-03 09:23:09.569558] Hi, Donald! Nice to meet you. [2020-09-03 09:23:20.076845] Bye, Donald! It was great talking to you. Providing a better greeting message \u00b6 The way how Hello World MLBox application was implemented, the greeting message is always the following: Nice to meet you. . We will update the implementation so that if this is not the first time Alice says hello , the MLBox will respond: Nice to see you again. . Modify the file examples/hello_world/build/hello_world.py . Update the function named get_greeting_message at line 14. It should have the following implementation: def get_greeting_message ( chat_file : str ) -> str : return \"Nice to meet you.\" if not os . path . exists ( chat_file ) else \"Nice to see you again.\" Since we updated a file in build subdirectory, we need to re-configure the MLBox: python -m mlbox_docker_run configure --mlbox=examples/hello_world --platform=examples/hello_world/platform/docker.yaml Now, run two hello task again: python -m mlbox_docker_run run --mlbox=examples/hello_world --platform=examples/hello_world/platform/docker.yaml --task=examples/hello_world/run/alice/hello.yaml The MLBox recognized it was not the first time it talked to Alice, and changed the greeting: [2020-09-03 09:13:14.236945] Hi, Alice! Nice to meet you. [2020-09-03 09:13:20.749831] Bye, Alice! It was great talking to you. [2020-09-03 09:32:41.369367] Hi, Alice! Nice to see you again.","title":"Hello World"},{"location":"getting-started/hello-world/#hello-world","text":"","title":"Hello World"},{"location":"getting-started/hello-world/#docker-runtime","text":"Hello World MLBox is an example of a docker-based MLBox, and docker runtime must be installed in a system. Installation guides for various operating systems can be found here . This example was tested on a system where users are in the docker group and run docker without sudo . To add yourself to a docker group, run the following: sudo groupadd docker # Add the docker group if it doesn't already exist. sudo gpasswd -a ${USER} docker # Add the connected user \"${USER}\" to the docker group. Change the user name to match your preferred user. sudo service docker restart # Restart the Docker daemon. newgrp docker # Either do a\u00c2 newgrp docker\u00c2 or log out/in to activate the changes to groups.","title":"Docker runtime"},{"location":"getting-started/hello-world/#host-python-environment","text":"Hello World is an example of a simple python program distributed as an MLBox. This tutorial covers the case when MLBox library and Hello World MLBox are cloned from the GitHub repository: git clone https://github.com/mlperf/mlbox ./mlbox cd ./mlbox Python >= 3.6 is required together with runners' python dependencies: virtualenv -p python3.8 ./env source ./env/bin/activate pip install typer mlspeclib export PYTHONPATH=$(pwd)/mlcommons_box:$(pwd)/runners/mlbox_singularity_run:$(pwd)/runners/mlbox_docker_run Optionally, setup host environment by providing the correct http_proxy and https_proxy environmental variables. export http_proxy=... export https_proxy=...","title":"Host python environment"},{"location":"getting-started/hello-world/#configuring-mlbox","text":"MLBoxes need to be configured before they can run. To do so, users need to run the MLBox runner with configure command providing path to a MLBox root directory and path to a platform configuration file. Hello World MLBox is a docker-based MLBox, so users provide path to a Docker platform configuration file that sets a number of parameters, including docker image name: python -m mlbox_docker_run configure --mlbox=examples/hello_world --platform=examples/hello_world/platform/docker.yaml Docker runner will build a docker image for the Hello World MLBox.","title":"Configuring MLBox"},{"location":"getting-started/hello-world/#running-mlbox","text":"In order to run MLBox, users need to provide the path to the root directory of the MLBox, platform configuration file and path to a task definition file. Run the following two commands one at a time: python -m mlbox_docker_run run --mlbox=examples/hello_world --platform=examples/hello_world/platform/docker.yaml --task=examples/hello_world/run/alice/hello.yaml python -m mlbox_docker_run run --mlbox=examples/hello_world --platform=examples/hello_world/platform/docker.yaml --task=examples/hello_world/run/alice/bye.yaml MLBox creates a file examples/hello_world/workspace/chats/chat_with_alice.txt that contains the following: [2020-09-03 09:13:14.236945] Hi, Alice! Nice to meet you. [2020-09-03 09:13:20.749831] Bye, Alice! It was great talking to you.","title":"Running MLBox"},{"location":"getting-started/hello-world/#modifying-mlbox","text":"","title":"Modifying MLBox"},{"location":"getting-started/hello-world/#adding-new-user","text":"Create a new file examples/hello_world/workspace/names/donald.txt with the following content: Donald . Create a new file examples/hello_world/run/donald/hello.yaml with the following content: schema_type : mlbox_invoke schema_version : 1.0.0 task_name : hello input_binding : name : $WORKSPACE/names/donald.txt output_binding : chat : $WORKSPACE/chats/chat_with_donald.txt Create a new file examples/hello_world/run/donald/bye.yaml with the following content: schema_type : mlbox_invoke schema_version : 1.0.0 task_name : bye input_binding : name : $WORKSPACE/names/donald.txt output_binding : chat : $WORKSPACE/chats/chat_with_donald.txt Run the following two commands one at a time: python -m mlbox_docker_run run --mlbox=examples/hello_world --platform=examples/hello_world/platform/docker.yaml --task=examples/hello_world/run/donald/hello.yaml python -m mlbox_docker_run run --mlbox=examples/hello_world --platform=examples/hello_world/platform/docker.yaml --task=examples/hello_world/run/donald/bye.yaml MLBox creates a file examples/hello_world/workspace/chats/chat_with_donald.txt that contains the following: [2020-09-03 09:23:09.569558] Hi, Donald! Nice to meet you. [2020-09-03 09:23:20.076845] Bye, Donald! It was great talking to you.","title":"Adding new user"},{"location":"getting-started/hello-world/#providing-a-better-greeting-message","text":"The way how Hello World MLBox application was implemented, the greeting message is always the following: Nice to meet you. . We will update the implementation so that if this is not the first time Alice says hello , the MLBox will respond: Nice to see you again. . Modify the file examples/hello_world/build/hello_world.py . Update the function named get_greeting_message at line 14. It should have the following implementation: def get_greeting_message ( chat_file : str ) -> str : return \"Nice to meet you.\" if not os . path . exists ( chat_file ) else \"Nice to see you again.\" Since we updated a file in build subdirectory, we need to re-configure the MLBox: python -m mlbox_docker_run configure --mlbox=examples/hello_world --platform=examples/hello_world/platform/docker.yaml Now, run two hello task again: python -m mlbox_docker_run run --mlbox=examples/hello_world --platform=examples/hello_world/platform/docker.yaml --task=examples/hello_world/run/alice/hello.yaml The MLBox recognized it was not the first time it talked to Alice, and changed the greeting: [2020-09-03 09:13:14.236945] Hi, Alice! Nice to meet you. [2020-09-03 09:13:20.749831] Bye, Alice! It was great talking to you. [2020-09-03 09:32:41.369367] Hi, Alice! Nice to see you again.","title":"Providing a better greeting message"},{"location":"getting-started/mnist/","text":"MNIST \u00b6 The MNIST dataset is a collection of 60,000 handwritten digits widely used for training statistical, Machine Learning and Deep Learning models. The MNIST MLBox example demonstrates how data scientists, ML and DL researchers and developers can package their training/validation/inference code as a MLBox to achieve portability and reproducibility. A data scientist has been working on a machine learning project. The goal is to train a simple neural network to classify collection of 60,000 small images into 10 classes. MNIST training code \u00b6 Training a ML model is a process involving multiple steps such as getting data, analyzing and cleaning data, splitting into train/validation/test data sets, running hyper-parameter optimization experiments and performing final model testing. It is a relatively small and well studied dataset that provides standard train/test split. In this simple example a developer needs to implement two steps - (1) downloading data and (2) training a model. We'll call these steps as tasks . Each task requires several parameters, such as URL of the data set that we need to download, location on a local disk where the data set will be serialized, path to a directory that will contain training artifacts such as logs and models. We can characterize these two tasks in the following way: - Data Download task: - Inputs : None. We'll assume the download URL is defined in the source code. - Outputs : Directory to serialize the data set ( data_dir ) and directory to serialize log files ( log_dir ). - Training task: - Inputs : Directory with MNIST data set ( data_dir ), training hyper-parameters defined in a file ( parameters_file ). - Outputs : Directory to store training results ( model_dir ) and directory to store log files ( log_dir ). We have intentionally made all input/output parameters to be file system artifacts. By doing so, we support reproducibility. Instead of command line arguments that can easily be lost, we store them in files. There are many different ways to implement the MNIST example. For simplicity, we assume the following: - We use one python file. - Task name (download, train) is a command line positional parameter. - Both tasks write logs, so it makes sense to add parameter accepting directory for log files. - The download task accepts additional data directory parameter. - The train task accepts such parameters as data and model directories, path to a file with hyper-parameter. - Configurable hyper-parameters are: (1) optimizer name, (2) number of training epochs and (3) global batch size. Then, our implementation could look like this. Parse command line and identify task. If it is download , call function that downloads data sets. If it is train , train a model. This is sort of single entrypoint implementation where we run one script asking to perform various tasks. We run our script (mnist.py) in the following way: python mnist.py download --data_dir=PATH --log_dir=PATH python mnist.py train --data_dir=PATH --log_dir=PATH --model_dir=PATH --parameters_file=PATH MLBox implementation \u00b6 Packaging our MNIST training script as a MLBox is done in several steps. We will be using a directory-based MLBox where a directory is structured in a certain way and contains specific files that make it MLBox. We need to create an empty directory on a local disk. Let's assume we call it mnist and we'll use {MLBOX_ROOT} to denote a full path to this directory. This is called a MLBox root directory. At this point this directory is empty: mnist/ Build location \u00b6 MLBox directory has a sub-directory called build ( {MLBOX_ROOT}/build ) that store project source files, resources required for training, other files to recreate run time (such as requirements.txt, docker and singularity recipes etc.). We need to create the build directory and copy two files: mnist.py that implements training and requirements.txt that lists python dependencies. By doing so, we are enforcing reproducibility. A developer of this MLBox wants to make it easier to run their training workload in a great variety of environments including universities, commercial companies, HPC-friendly organizations such as national labs. One way to achieve it is to use container runtime such as docker or singularity. So, we'll provide both docker file and singularity recipe that we'll put into build directory as well. Thus, we'll make this directory a build context. The mlbox directory now looks like: mnist/ build/ mnist.py requirements.txt Dockerfile Singularity.recipe A good test at this point would be ensure that project is runnable from the build directory, and docker and singularity images can be built. MLBox definition file \u00b6 At this point we are ready to create a MLBox definition file. This is the first definition file that makes some folder a MLBox. This is a YAML file that provides information such as name, author, version, named as mlbox.yaml and located in the root MLBox directory . The most important section is the one that lists what tasks are implemented in this MLBox: schema_version : 1.0.0 # We use MLSpec library to validate YAML definition files. This is the schema_type : mlbox_root # specification of the schema that this file must be consistent with. name : mnist # Name of this MLBox. author : MLPerf Best Practices Working Group # A developer of the MLBox. version : 0.1.0 # MLBox version. mlbox_spec_version : 0.1.0 # TODO: What is it? tasks : # Tasks are defined in external YAML files located in tasks folder. - 'tasks/download.yaml' # \"Download data set\" task definition file. - 'tasks/train.yaml' # \"Training a model\" task definition file. At this point, the directory looks like: mnist/ build/ {mnist.py, requirements.txt, Dockerfile, Singularity.recipe} mlbox.yaml Task definition file \u00b6 The MLBox definition file references two tasks defined in the tasks subdirectory. Each YAML file there defines a task supported by the MLBox. Task files are named the same as tasks. We need to create a tasks directory and two files inside that directory - download.yaml and train.yaml . Each task file defines input and output specifications for each task. The download task (download.yaml) is defined: schema_version : 1.0.0 # Task schema definition. Leave this two fields as is. schema_type : mlbox_task inputs : [] # Since this task does not have any inputs, the section is empty. outputs : # This task produces two artifacts - downloaded data and log files. - name : data_dir # This parameter accepts path to a directory where data set will be serialized. type : directory # We implicitly specify that this is a directory - name : log_dir # This parameter accepts path to a directory with log files this task writes. type : directory # We implicitly specify that this is a directory Names of these parameters are the same that are accepted by mnist.py: python mnist.py download --data_dir=PATH --log_dir=PATH The train task ( train.yaml ) is defined in the following way: schema_version : 1.0.0 # Task schema definition. Leave this two fields as is. schema_type : mlbox_task inputs : # These are the task inputs. - name : data_dir # This parameter accepts path to a directory where data set will be serialized. type : directory # We implicitly specify that this is a directory - name : parameters_file # A file containing training hyper-parameters. type : file # This is a file. outputs : # These are the task outputs. - name : log_dir # This parameter accepts path to a directory with log files this task writes. type : directory # We implicitly specify that this is a directory - name : model_dir # Path to a directory where training artifacts are stored. type : directory # We implicitly specify that this is a directory Names of these parameters are the same that are accepted by mnist.py: python mnist.py train --data_dir=PATH --log_dir=PATH --model_dir=PATH --parameters_file=PATH At this point, the MLBox directory looks like: mnist/ build/ {mnist.py, requirements.txt, Dockerfile, Singularity.recipe} tasks/ {download.yaml, train.yaml} mlbox.yaml Workspace \u00b6 The workspace is a directory inside MLBox ( workspace ) where, by default, input/output file system artifacts are stored. The are multiple reasons to have one. One is to formally have default place for data sets, configuration and log files etc. Having all these parameters in one place makes it simpler to run MLBoxes on remote hosts and then sync results back to users' local machines. We need to be able to provide collection of hyper-parameters and formally define a directory to store logs, models and MNIST data set. To do so, we create the directory tree workspace/parameters , and then create a file ( default.parameters.yaml ) with the following content: optimizer : \"adam\" train_epochs : 5 batch_size : 32 At this point, the MLBox directory looks like: mnist/ build/ {mnist.py, requirements.txt, Dockerfile, Singularity.recipe} tasks/ {download.yaml, train.yaml} workspace/ parameters/ default.parameters.yaml mlbox.yaml Run configurations \u00b6 MLBox definition file ( mlbox.yaml ) provides paths to task definition files that formally define tasks input/output parameters. A run configuration assigns values to task parameters. One reason to define and \"implement\" parameters in different files is to be able to provide multiple configurations for the same task. One example could be one-GPU training configuration and 8-GPU training configuration. Since we have two tasks - download and train - we need to define at least two run configurations. Run configurations are defined in the run subdirectory. Run configuration for the download task looks like: schema_type : mlbox_invoke # Run (invoke) schema definition. Leave this two fields as is. schema_version : 1.0.0 task_name : download # Task name input_binding : {} # No input parameters for this task. output_binding : # Output parameters, format is \"parameter: value\" data_dir : $WORKSPACE/data # Path to serialize downloaded MNIST data set log_dir : $WORKSPACE/download_logs # Path to log files. The $WORKSPACE token is replaced with actual path to the MLBox workspace. File system paths are relative to the workspace directory. This makes it possible to provide absolute paths for cases when data sets are stored on some shared drives. Run configuration for the train task looks like: schema_type : mlbox_invoke # Run (invoke) schema definition. Leave this two fields as is. schema_version : 1.0.0 task_name : train # Task name input_binding : # Input parameters (name: value) data_dir : $WORKSPACE/data parameters_file : $WORKSPACE/parameters/default.parameters.yaml output_binding : # Output parameters (name: value) log_dir : $WORKSPACE/train_logs model_dir : $WORKSPACE/model At this point, the MLBox directory looks like: mnist/ build/ {mnist.py, requirements.txt, Dockerfile, Singularity.recipe} tasks/ {download.yaml, train.yaml} workspace/parameters/default.parameters.yaml run/ download.yaml train.yaml mlbox.yaml Platform configurations \u00b6 Platform configurations define how MLBoxes run. Docker, Singularity, SSH and cloud runners have their own configurations. For instance, Docker platform configuration at minimum provides image name and docker executable (docker / nvidia-docker). SSH platform configuration could provide IP address of a remote host, login credentials etc. Platform configurations are supposed to be used by runners, and each runner has its own platform schema. The Runners documentation section provides detailed description of reference runners together with platform configuration schemas. Since we wanted to support Docker and Singularity runtimes, we provide docker.yaml and singularity.yaml files in the platform subdirectory that is default location to store these types of files. Docker platform configuration is the following: schema_version : 1.0.0 schema_type : mlbox_docker image : mlperf/mlbox:mnist # Docker image name docker_runtime : docker # Docker executable: docker or nvidia-docker Singularity platform configuration is the following: schema_version : 1.0.0 schema_type : mlbox_singularity image : /opt/singularity/mlperf_mlbox_mnist-0.01.simg # Path to or name of a Singularity image. At this point, the MLBox directory looks like: mnist/ build/ {mnist.py, requirements.txt, Dockerfile, Singularity.recipe} tasks/ {download.yaml, train.yaml} workspace/parameters/default.parameters.yaml run/ {download.yaml, train.yaml} platform/ docker.yaml singularity.yaml mlbox.yaml MNIST MLBox directory structure summary \u00b6 mnist/ # MLBox root directory. build/ # Project source code, resource files, Docker/Singularity recipes. mnist.py # Python source code training simple neural network using MNIST data set. requirements.txt # Python project dependencies. Dockerfile # Docker recipe. Singularity.recipe # Singularity recipe. tasks/ # Task definition files - define functionality that MLBox supports download.yaml # Download MNIST data set. train.yaml # Train neural network. workspace/ # Default location for data sets, logs, models, parameter files. parameters/ # Model hyper-parameters can be stored at any location. default.parameters.yaml # This is just what is used in this implementation. run/ # Run configurations - bind task parameters and values. download.yaml # Concrete run specification for the download task. train.yaml # Concrete run specification for the train task. platform/ # Platform definition files - define how MLBox runs. docker.yaml # Docker runtime definition. singularity.yaml # Singularity runtime definition. mlbox.yaml # MLBox definition file. Running MNIST MLBox \u00b6 This tutorial covers the case when MLBox library and MNIST MLBox are cloned from the GitHub repository: git clone https://github.com/mlperf/mlbox ./mlbox cd ./mlbox Python >= 3.6 is required together with runners' python dependencies: virtualenv -p python3.8 ./env source ./env/bin/activate pip install typer mlspeclib export PYTHONPATH=$(pwd)/mlcommons_box:$(pwd)/runners/mlbox_singularity_run:$(pwd)/runners/mlbox_docker_run:$(pwd)/runners/mlbox_ssh_run Optionally, setup host environment by providing the correct http_proxy and https_proxy environmental variables. export http_proxy=... export https_proxy=... Before running MNIST MLBox below, it is probably a good idea to remove tasks' outputs from previous runs that are located in examples/mnist/workspace . All directories except parameters can be removed. Docker runner \u00b6 Configure MNIST MLBox: python -m mlbox_docker_run configure --mlbox=examples/mnist --platform=examples/mnist/platform/docker.yaml Run two tasks - download (download data) and train (train tiny neural network): python -m mlbox_docker_run run --mlbox=examples/mnist --platform=examples/mnist/platform/docker.yaml --task=examples/mnist/run/download.yaml python -m mlbox_docker_run run --mlbox=examples/mnist --platform=examples/mnist/platform/docker.yaml --task=examples/mnist/run/train.yaml Singularity runner \u00b6 Update path to store Singularity image. Open examples/mnist/platform/singularity.yaml and update the image value that is set by default to /opt/singularity/mlperf_mlbox_mnist-0.01.simg (relative paths are supported, they are relative to examples/mnist/workspace ). Configure MNIST MLBox: python -m mlbox_singularity_run configure --mlbox=examples/mnist --platform=examples/mnist/platform/singularity.yaml Run two tasks - download (download data) and train (train tiny neural network): python -m mlbox_singularity_run run --mlbox=examples/mnist --platform=examples/mnist/platform/singularity.yaml --task=examples/mnist/run/download.yaml python -m mlbox_singularity_run run --mlbox=examples/mnist --platform=examples/mnist/platform/singularity.yaml --task=examples/mnist/run/train.yaml","title":"MNIST"},{"location":"getting-started/mnist/#mnist","text":"The MNIST dataset is a collection of 60,000 handwritten digits widely used for training statistical, Machine Learning and Deep Learning models. The MNIST MLBox example demonstrates how data scientists, ML and DL researchers and developers can package their training/validation/inference code as a MLBox to achieve portability and reproducibility. A data scientist has been working on a machine learning project. The goal is to train a simple neural network to classify collection of 60,000 small images into 10 classes.","title":"MNIST"},{"location":"getting-started/mnist/#mnist-training-code","text":"Training a ML model is a process involving multiple steps such as getting data, analyzing and cleaning data, splitting into train/validation/test data sets, running hyper-parameter optimization experiments and performing final model testing. It is a relatively small and well studied dataset that provides standard train/test split. In this simple example a developer needs to implement two steps - (1) downloading data and (2) training a model. We'll call these steps as tasks . Each task requires several parameters, such as URL of the data set that we need to download, location on a local disk where the data set will be serialized, path to a directory that will contain training artifacts such as logs and models. We can characterize these two tasks in the following way: - Data Download task: - Inputs : None. We'll assume the download URL is defined in the source code. - Outputs : Directory to serialize the data set ( data_dir ) and directory to serialize log files ( log_dir ). - Training task: - Inputs : Directory with MNIST data set ( data_dir ), training hyper-parameters defined in a file ( parameters_file ). - Outputs : Directory to store training results ( model_dir ) and directory to store log files ( log_dir ). We have intentionally made all input/output parameters to be file system artifacts. By doing so, we support reproducibility. Instead of command line arguments that can easily be lost, we store them in files. There are many different ways to implement the MNIST example. For simplicity, we assume the following: - We use one python file. - Task name (download, train) is a command line positional parameter. - Both tasks write logs, so it makes sense to add parameter accepting directory for log files. - The download task accepts additional data directory parameter. - The train task accepts such parameters as data and model directories, path to a file with hyper-parameter. - Configurable hyper-parameters are: (1) optimizer name, (2) number of training epochs and (3) global batch size. Then, our implementation could look like this. Parse command line and identify task. If it is download , call function that downloads data sets. If it is train , train a model. This is sort of single entrypoint implementation where we run one script asking to perform various tasks. We run our script (mnist.py) in the following way: python mnist.py download --data_dir=PATH --log_dir=PATH python mnist.py train --data_dir=PATH --log_dir=PATH --model_dir=PATH --parameters_file=PATH","title":"MNIST training code"},{"location":"getting-started/mnist/#mlbox-implementation","text":"Packaging our MNIST training script as a MLBox is done in several steps. We will be using a directory-based MLBox where a directory is structured in a certain way and contains specific files that make it MLBox. We need to create an empty directory on a local disk. Let's assume we call it mnist and we'll use {MLBOX_ROOT} to denote a full path to this directory. This is called a MLBox root directory. At this point this directory is empty: mnist/","title":"MLBox implementation"},{"location":"getting-started/mnist/#build-location","text":"MLBox directory has a sub-directory called build ( {MLBOX_ROOT}/build ) that store project source files, resources required for training, other files to recreate run time (such as requirements.txt, docker and singularity recipes etc.). We need to create the build directory and copy two files: mnist.py that implements training and requirements.txt that lists python dependencies. By doing so, we are enforcing reproducibility. A developer of this MLBox wants to make it easier to run their training workload in a great variety of environments including universities, commercial companies, HPC-friendly organizations such as national labs. One way to achieve it is to use container runtime such as docker or singularity. So, we'll provide both docker file and singularity recipe that we'll put into build directory as well. Thus, we'll make this directory a build context. The mlbox directory now looks like: mnist/ build/ mnist.py requirements.txt Dockerfile Singularity.recipe A good test at this point would be ensure that project is runnable from the build directory, and docker and singularity images can be built.","title":"Build location"},{"location":"getting-started/mnist/#mlbox-definition-file","text":"At this point we are ready to create a MLBox definition file. This is the first definition file that makes some folder a MLBox. This is a YAML file that provides information such as name, author, version, named as mlbox.yaml and located in the root MLBox directory . The most important section is the one that lists what tasks are implemented in this MLBox: schema_version : 1.0.0 # We use MLSpec library to validate YAML definition files. This is the schema_type : mlbox_root # specification of the schema that this file must be consistent with. name : mnist # Name of this MLBox. author : MLPerf Best Practices Working Group # A developer of the MLBox. version : 0.1.0 # MLBox version. mlbox_spec_version : 0.1.0 # TODO: What is it? tasks : # Tasks are defined in external YAML files located in tasks folder. - 'tasks/download.yaml' # \"Download data set\" task definition file. - 'tasks/train.yaml' # \"Training a model\" task definition file. At this point, the directory looks like: mnist/ build/ {mnist.py, requirements.txt, Dockerfile, Singularity.recipe} mlbox.yaml","title":"MLBox definition file"},{"location":"getting-started/mnist/#task-definition-file","text":"The MLBox definition file references two tasks defined in the tasks subdirectory. Each YAML file there defines a task supported by the MLBox. Task files are named the same as tasks. We need to create a tasks directory and two files inside that directory - download.yaml and train.yaml . Each task file defines input and output specifications for each task. The download task (download.yaml) is defined: schema_version : 1.0.0 # Task schema definition. Leave this two fields as is. schema_type : mlbox_task inputs : [] # Since this task does not have any inputs, the section is empty. outputs : # This task produces two artifacts - downloaded data and log files. - name : data_dir # This parameter accepts path to a directory where data set will be serialized. type : directory # We implicitly specify that this is a directory - name : log_dir # This parameter accepts path to a directory with log files this task writes. type : directory # We implicitly specify that this is a directory Names of these parameters are the same that are accepted by mnist.py: python mnist.py download --data_dir=PATH --log_dir=PATH The train task ( train.yaml ) is defined in the following way: schema_version : 1.0.0 # Task schema definition. Leave this two fields as is. schema_type : mlbox_task inputs : # These are the task inputs. - name : data_dir # This parameter accepts path to a directory where data set will be serialized. type : directory # We implicitly specify that this is a directory - name : parameters_file # A file containing training hyper-parameters. type : file # This is a file. outputs : # These are the task outputs. - name : log_dir # This parameter accepts path to a directory with log files this task writes. type : directory # We implicitly specify that this is a directory - name : model_dir # Path to a directory where training artifacts are stored. type : directory # We implicitly specify that this is a directory Names of these parameters are the same that are accepted by mnist.py: python mnist.py train --data_dir=PATH --log_dir=PATH --model_dir=PATH --parameters_file=PATH At this point, the MLBox directory looks like: mnist/ build/ {mnist.py, requirements.txt, Dockerfile, Singularity.recipe} tasks/ {download.yaml, train.yaml} mlbox.yaml","title":"Task definition file"},{"location":"getting-started/mnist/#workspace","text":"The workspace is a directory inside MLBox ( workspace ) where, by default, input/output file system artifacts are stored. The are multiple reasons to have one. One is to formally have default place for data sets, configuration and log files etc. Having all these parameters in one place makes it simpler to run MLBoxes on remote hosts and then sync results back to users' local machines. We need to be able to provide collection of hyper-parameters and formally define a directory to store logs, models and MNIST data set. To do so, we create the directory tree workspace/parameters , and then create a file ( default.parameters.yaml ) with the following content: optimizer : \"adam\" train_epochs : 5 batch_size : 32 At this point, the MLBox directory looks like: mnist/ build/ {mnist.py, requirements.txt, Dockerfile, Singularity.recipe} tasks/ {download.yaml, train.yaml} workspace/ parameters/ default.parameters.yaml mlbox.yaml","title":"Workspace"},{"location":"getting-started/mnist/#run-configurations","text":"MLBox definition file ( mlbox.yaml ) provides paths to task definition files that formally define tasks input/output parameters. A run configuration assigns values to task parameters. One reason to define and \"implement\" parameters in different files is to be able to provide multiple configurations for the same task. One example could be one-GPU training configuration and 8-GPU training configuration. Since we have two tasks - download and train - we need to define at least two run configurations. Run configurations are defined in the run subdirectory. Run configuration for the download task looks like: schema_type : mlbox_invoke # Run (invoke) schema definition. Leave this two fields as is. schema_version : 1.0.0 task_name : download # Task name input_binding : {} # No input parameters for this task. output_binding : # Output parameters, format is \"parameter: value\" data_dir : $WORKSPACE/data # Path to serialize downloaded MNIST data set log_dir : $WORKSPACE/download_logs # Path to log files. The $WORKSPACE token is replaced with actual path to the MLBox workspace. File system paths are relative to the workspace directory. This makes it possible to provide absolute paths for cases when data sets are stored on some shared drives. Run configuration for the train task looks like: schema_type : mlbox_invoke # Run (invoke) schema definition. Leave this two fields as is. schema_version : 1.0.0 task_name : train # Task name input_binding : # Input parameters (name: value) data_dir : $WORKSPACE/data parameters_file : $WORKSPACE/parameters/default.parameters.yaml output_binding : # Output parameters (name: value) log_dir : $WORKSPACE/train_logs model_dir : $WORKSPACE/model At this point, the MLBox directory looks like: mnist/ build/ {mnist.py, requirements.txt, Dockerfile, Singularity.recipe} tasks/ {download.yaml, train.yaml} workspace/parameters/default.parameters.yaml run/ download.yaml train.yaml mlbox.yaml","title":"Run configurations"},{"location":"getting-started/mnist/#platform-configurations","text":"Platform configurations define how MLBoxes run. Docker, Singularity, SSH and cloud runners have their own configurations. For instance, Docker platform configuration at minimum provides image name and docker executable (docker / nvidia-docker). SSH platform configuration could provide IP address of a remote host, login credentials etc. Platform configurations are supposed to be used by runners, and each runner has its own platform schema. The Runners documentation section provides detailed description of reference runners together with platform configuration schemas. Since we wanted to support Docker and Singularity runtimes, we provide docker.yaml and singularity.yaml files in the platform subdirectory that is default location to store these types of files. Docker platform configuration is the following: schema_version : 1.0.0 schema_type : mlbox_docker image : mlperf/mlbox:mnist # Docker image name docker_runtime : docker # Docker executable: docker or nvidia-docker Singularity platform configuration is the following: schema_version : 1.0.0 schema_type : mlbox_singularity image : /opt/singularity/mlperf_mlbox_mnist-0.01.simg # Path to or name of a Singularity image. At this point, the MLBox directory looks like: mnist/ build/ {mnist.py, requirements.txt, Dockerfile, Singularity.recipe} tasks/ {download.yaml, train.yaml} workspace/parameters/default.parameters.yaml run/ {download.yaml, train.yaml} platform/ docker.yaml singularity.yaml mlbox.yaml","title":"Platform configurations"},{"location":"getting-started/mnist/#mnist-mlbox-directory-structure-summary","text":"mnist/ # MLBox root directory. build/ # Project source code, resource files, Docker/Singularity recipes. mnist.py # Python source code training simple neural network using MNIST data set. requirements.txt # Python project dependencies. Dockerfile # Docker recipe. Singularity.recipe # Singularity recipe. tasks/ # Task definition files - define functionality that MLBox supports download.yaml # Download MNIST data set. train.yaml # Train neural network. workspace/ # Default location for data sets, logs, models, parameter files. parameters/ # Model hyper-parameters can be stored at any location. default.parameters.yaml # This is just what is used in this implementation. run/ # Run configurations - bind task parameters and values. download.yaml # Concrete run specification for the download task. train.yaml # Concrete run specification for the train task. platform/ # Platform definition files - define how MLBox runs. docker.yaml # Docker runtime definition. singularity.yaml # Singularity runtime definition. mlbox.yaml # MLBox definition file.","title":"MNIST MLBox directory structure summary"},{"location":"getting-started/mnist/#running-mnist-mlbox","text":"This tutorial covers the case when MLBox library and MNIST MLBox are cloned from the GitHub repository: git clone https://github.com/mlperf/mlbox ./mlbox cd ./mlbox Python >= 3.6 is required together with runners' python dependencies: virtualenv -p python3.8 ./env source ./env/bin/activate pip install typer mlspeclib export PYTHONPATH=$(pwd)/mlcommons_box:$(pwd)/runners/mlbox_singularity_run:$(pwd)/runners/mlbox_docker_run:$(pwd)/runners/mlbox_ssh_run Optionally, setup host environment by providing the correct http_proxy and https_proxy environmental variables. export http_proxy=... export https_proxy=... Before running MNIST MLBox below, it is probably a good idea to remove tasks' outputs from previous runs that are located in examples/mnist/workspace . All directories except parameters can be removed.","title":"Running MNIST MLBox"},{"location":"getting-started/mnist/#docker-runner","text":"Configure MNIST MLBox: python -m mlbox_docker_run configure --mlbox=examples/mnist --platform=examples/mnist/platform/docker.yaml Run two tasks - download (download data) and train (train tiny neural network): python -m mlbox_docker_run run --mlbox=examples/mnist --platform=examples/mnist/platform/docker.yaml --task=examples/mnist/run/download.yaml python -m mlbox_docker_run run --mlbox=examples/mnist --platform=examples/mnist/platform/docker.yaml --task=examples/mnist/run/train.yaml","title":"Docker runner"},{"location":"getting-started/mnist/#singularity-runner","text":"Update path to store Singularity image. Open examples/mnist/platform/singularity.yaml and update the image value that is set by default to /opt/singularity/mlperf_mlbox_mnist-0.01.simg (relative paths are supported, they are relative to examples/mnist/workspace ). Configure MNIST MLBox: python -m mlbox_singularity_run configure --mlbox=examples/mnist --platform=examples/mnist/platform/singularity.yaml Run two tasks - download (download data) and train (train tiny neural network): python -m mlbox_singularity_run run --mlbox=examples/mnist --platform=examples/mnist/platform/singularity.yaml --task=examples/mnist/run/download.yaml python -m mlbox_singularity_run run --mlbox=examples/mnist --platform=examples/mnist/platform/singularity.yaml --task=examples/mnist/run/train.yaml","title":"Singularity runner"},{"location":"runners/","text":"Runners \u00b6 A runner is a tool that runs MLBox instances on one or multiple platforms. Examples of platforms are docker and singularity containers, remote hosts, virtual machines in the cloud, etc. A platform is configured in a platform configuration file. An MLBox can provide reference platform configurations that users can modify to meet requirements of their infrastructures. MLBox standard requires that all runners implement mandatory functionality. All reference runners implement it. Users can develop their own runners to meet their specific requirements, such as security, authentication and authorization policies and others. Reference MLBox runners \u00b6 Reference MLBox runners are: - Docker Runner : Run MLBoxes using docker runtime. - Singularity Runner : Run MLBoxes using singularity runtime. - SSH Runner : Run MLBox on a remote host. SSH Runner uses other runners, such as Docker or Singularity runners, to run MLBoxes on remote hosts. Runner commands \u00b6 Each runner exposes mandatory and optional functionality through a set of commands. This is similar to, for instance, how Git implements its API ( git follows by a specific command such as checkout , pull , push etc). Mandatory commands are configure and run : - configure : Configure MLBox. Exact functionality depends on a runner type, but the goal is to ensure that MLBox is ready to run. The following are the examples of what can be done at configure phase: build docker or singularity container, create python virtual environment, allocate and configure virtual machine in the cloud, copy MLBox to a remote host etc. Once configuration is successfully completed, it is assumed a runner can run MLBox. - run : Run MLBox's task. Reference MLBox runners recognize three parameters - mlbox, platform and task. - mlbox : Path to MLBox root directory. In future versions, this can be a MLBox URI with a specific protocol. Runners could support various MLBox implementations (excluding reference directory-based) such as docker/singularity containers, GitHub repositories, compressed archives and others. - platform : Path to a YAML-based platform configuration file. If not present, MLBox runner should use the default platforms to run an MLBox, or select the most appropriate or available in a user environment. - task : Path to a YAML-based task specification file. If not present, MLBox can run the default task. Command line interface \u00b6 One way to run an MLBox is to follow the following template supported by all reference runners: python -m RUNNER_PACKAGE --mlbox=MLBOX_ROOT_DIRECTORY --platform=PLATFORM_FILE_PATH --task=TASK_FILE_PATH Example command to configure MNIST Docker-based MLBox: python -m mlbox_docker_run configure --mlbox=examples/mnist --platform=examples/mnist/platform/docker.yaml Example command to run two tasks implemented by the MNIST Docker-based MLBox: python -m mlbox_docker_run run --mlbox=examples/mnist --platform=examples/mnist/platform/docker.yaml --task=examples/mnist/run/download.yaml python -m mlbox_docker_run run --mlbox=examples/mnist --platform=examples/mnist/platform/docker.yaml --task=examples/mnist/run/train.yaml","title":"Runners"},{"location":"runners/#runners","text":"A runner is a tool that runs MLBox instances on one or multiple platforms. Examples of platforms are docker and singularity containers, remote hosts, virtual machines in the cloud, etc. A platform is configured in a platform configuration file. An MLBox can provide reference platform configurations that users can modify to meet requirements of their infrastructures. MLBox standard requires that all runners implement mandatory functionality. All reference runners implement it. Users can develop their own runners to meet their specific requirements, such as security, authentication and authorization policies and others.","title":"Runners"},{"location":"runners/#reference-mlbox-runners","text":"Reference MLBox runners are: - Docker Runner : Run MLBoxes using docker runtime. - Singularity Runner : Run MLBoxes using singularity runtime. - SSH Runner : Run MLBox on a remote host. SSH Runner uses other runners, such as Docker or Singularity runners, to run MLBoxes on remote hosts.","title":"Reference MLBox runners"},{"location":"runners/#runner-commands","text":"Each runner exposes mandatory and optional functionality through a set of commands. This is similar to, for instance, how Git implements its API ( git follows by a specific command such as checkout , pull , push etc). Mandatory commands are configure and run : - configure : Configure MLBox. Exact functionality depends on a runner type, but the goal is to ensure that MLBox is ready to run. The following are the examples of what can be done at configure phase: build docker or singularity container, create python virtual environment, allocate and configure virtual machine in the cloud, copy MLBox to a remote host etc. Once configuration is successfully completed, it is assumed a runner can run MLBox. - run : Run MLBox's task. Reference MLBox runners recognize three parameters - mlbox, platform and task. - mlbox : Path to MLBox root directory. In future versions, this can be a MLBox URI with a specific protocol. Runners could support various MLBox implementations (excluding reference directory-based) such as docker/singularity containers, GitHub repositories, compressed archives and others. - platform : Path to a YAML-based platform configuration file. If not present, MLBox runner should use the default platforms to run an MLBox, or select the most appropriate or available in a user environment. - task : Path to a YAML-based task specification file. If not present, MLBox can run the default task.","title":"Runner commands"},{"location":"runners/#command-line-interface","text":"One way to run an MLBox is to follow the following template supported by all reference runners: python -m RUNNER_PACKAGE --mlbox=MLBOX_ROOT_DIRECTORY --platform=PLATFORM_FILE_PATH --task=TASK_FILE_PATH Example command to configure MNIST Docker-based MLBox: python -m mlbox_docker_run configure --mlbox=examples/mnist --platform=examples/mnist/platform/docker.yaml Example command to run two tasks implemented by the MNIST Docker-based MLBox: python -m mlbox_docker_run run --mlbox=examples/mnist --platform=examples/mnist/platform/docker.yaml --task=examples/mnist/run/download.yaml python -m mlbox_docker_run run --mlbox=examples/mnist --platform=examples/mnist/platform/docker.yaml --task=examples/mnist/run/train.yaml","title":"Command line interface"},{"location":"runners/docker-runner/","text":"Docker Runner \u00b6 Docker runner uses docker/nvidia-docker to run MLBoxes. It supports two mandatory commands - configure and run with standard arguments - mlbox , platform and task . Docker platform configuration is used to configure docker runner. Platform Configuration File \u00b6 Docker platform configuration file is a YAML file that follows mlbox_docker ML schema. The configuration file for the reference MNIST MLBox is the following: schema_version : 1.0.0 schema_type : mlbox_docker image : mlperf/mlbox:mnist # Docker image name docker_runtime : docker # Docker executable: docker or nvidia-docker Additional configuration \u00b6 In current implementation, Docker runner uses http_proxy and https_proxy environmental variables (if set) during configure and run phases: - configure : docker build ... --build-args http_proxy=${http_proxy} --build-args https_proxy=${https_proxy} ... - run : docker run ... -e http_proxy=${http_proxy} -e https_proxy=${https_proxy} ... Build command \u00b6 Docker runner uses {MLBOX_ROOT}/build directory as the build context directory. This implies that all files that must be packaged in a docker image, must be located in that directory, including source files, python requirements, resource files, ML models etc. The docker recipe must have the standard name Dockerfile . In current implementation, only docker build is supported (i.e., Dockerfile must present). In future releases, Docker runner will support docker pull as well. Docker runner under the hood runs the following command line: cd {build_path}; docker build {env_args} -t {image_name} -f Dockerfile . where: - {build_path} is {MLBOX_ROOT}/build root directory. - {env_args} is the arguments retrieved from user environment, currently, only http_proxy and https_proxy are supported. - {image_name} is the image name from the platform configuration file. Run command \u00b6 Docker runner runs the following command: {docker_runtime} run --rm --net=host --privileged=true {volumes} {env_args} {image_name} {args} where: - {docker_exec} is the docker_runtime value from the Docker platform configuration file. - {volumes} are the mount points that MLBox library automatically constructed based upon task input/output specifications. - {env_args} is the arguments retrieved from user environment, currently, only http_proxy and https_proxy are supported. - {image_name} is the image name from the platform configuration file. - {args} is the task command line arguments, constructed automatically by the MLBox library.","title":"Docker Runner"},{"location":"runners/docker-runner/#docker-runner","text":"Docker runner uses docker/nvidia-docker to run MLBoxes. It supports two mandatory commands - configure and run with standard arguments - mlbox , platform and task . Docker platform configuration is used to configure docker runner.","title":"Docker Runner"},{"location":"runners/docker-runner/#platform-configuration-file","text":"Docker platform configuration file is a YAML file that follows mlbox_docker ML schema. The configuration file for the reference MNIST MLBox is the following: schema_version : 1.0.0 schema_type : mlbox_docker image : mlperf/mlbox:mnist # Docker image name docker_runtime : docker # Docker executable: docker or nvidia-docker","title":"Platform Configuration File"},{"location":"runners/docker-runner/#additional-configuration","text":"In current implementation, Docker runner uses http_proxy and https_proxy environmental variables (if set) during configure and run phases: - configure : docker build ... --build-args http_proxy=${http_proxy} --build-args https_proxy=${https_proxy} ... - run : docker run ... -e http_proxy=${http_proxy} -e https_proxy=${https_proxy} ...","title":"Additional configuration"},{"location":"runners/docker-runner/#build-command","text":"Docker runner uses {MLBOX_ROOT}/build directory as the build context directory. This implies that all files that must be packaged in a docker image, must be located in that directory, including source files, python requirements, resource files, ML models etc. The docker recipe must have the standard name Dockerfile . In current implementation, only docker build is supported (i.e., Dockerfile must present). In future releases, Docker runner will support docker pull as well. Docker runner under the hood runs the following command line: cd {build_path}; docker build {env_args} -t {image_name} -f Dockerfile . where: - {build_path} is {MLBOX_ROOT}/build root directory. - {env_args} is the arguments retrieved from user environment, currently, only http_proxy and https_proxy are supported. - {image_name} is the image name from the platform configuration file.","title":"Build command"},{"location":"runners/docker-runner/#run-command","text":"Docker runner runs the following command: {docker_runtime} run --rm --net=host --privileged=true {volumes} {env_args} {image_name} {args} where: - {docker_exec} is the docker_runtime value from the Docker platform configuration file. - {volumes} are the mount points that MLBox library automatically constructed based upon task input/output specifications. - {env_args} is the arguments retrieved from user environment, currently, only http_proxy and https_proxy are supported. - {image_name} is the image name from the platform configuration file. - {args} is the task command line arguments, constructed automatically by the MLBox library.","title":"Run command"},{"location":"runners/singularity-runner/","text":"Singularity Runner \u00b6 Singularity runner uses singularity to run MLBoxes. It supports two mandatory commands - configure and run with standard arguments - mlbox , platform and task . Singularity platform configuration is used to configure Singularity runner. Platform Configuration File \u00b6 Singularity platform configuration file is a YAML file that follows mlbox_singularity ML schema. The configuration file for the reference MNIST MLBox is the following: schema_version : 1.0.0 schema_type : mlbox_singularity image : /opt/singularity/mlperf_mlbox_mnist-0.01.simg # Path to or name of a Singularity image. The image field above is a path to a singularity container. It is relative to {MLBOX_ROOT}/workspace : - By default, containers are stored in {MLBOX_ROOT}/workspace if image is a file name. - If it is a relative path, it is relative to {MLBOX_ROOT}/workspace . - Absolute paths (starting with /) are used as is. In the example above, Singularity image is stored in the directory outside of the {MLBOX_ROOT} to avoid copying it back to the user host when using runners such as SSH. Build command \u00b6 Singularity runner uses {MLBOX_ROOT}/build directory as the build context directory. This implies that all files that must be packaged in a singularity image, must be located in that directory, including source files, python requirements, resource files, ML models etc. The singularity recipe must have the standard name Singularity.recipe . Singularity runner under the hood runs the following command line: cd {build_path}; singularity build --fakeroot {image_path} Singularity.recipe where: - {build_path} is {MLBOX_ROOT}/build root directory. - {image_path} is the path to Singularity image that is computed as described above. Run command \u00b6 Singularity runner runs the following command: singularity run {volumes} {image_path} {args} where: - {volumes} are the mount points that MLBox library automatically constructed based upon task input/output specifications. - {image_path} is the path to Singularity image that is computed as described above. - {args} is the task command line arguments, constructed automatically by the MLBox library.","title":"Singularity Runner"},{"location":"runners/singularity-runner/#singularity-runner","text":"Singularity runner uses singularity to run MLBoxes. It supports two mandatory commands - configure and run with standard arguments - mlbox , platform and task . Singularity platform configuration is used to configure Singularity runner.","title":"Singularity Runner"},{"location":"runners/singularity-runner/#platform-configuration-file","text":"Singularity platform configuration file is a YAML file that follows mlbox_singularity ML schema. The configuration file for the reference MNIST MLBox is the following: schema_version : 1.0.0 schema_type : mlbox_singularity image : /opt/singularity/mlperf_mlbox_mnist-0.01.simg # Path to or name of a Singularity image. The image field above is a path to a singularity container. It is relative to {MLBOX_ROOT}/workspace : - By default, containers are stored in {MLBOX_ROOT}/workspace if image is a file name. - If it is a relative path, it is relative to {MLBOX_ROOT}/workspace . - Absolute paths (starting with /) are used as is. In the example above, Singularity image is stored in the directory outside of the {MLBOX_ROOT} to avoid copying it back to the user host when using runners such as SSH.","title":"Platform Configuration File"},{"location":"runners/singularity-runner/#build-command","text":"Singularity runner uses {MLBOX_ROOT}/build directory as the build context directory. This implies that all files that must be packaged in a singularity image, must be located in that directory, including source files, python requirements, resource files, ML models etc. The singularity recipe must have the standard name Singularity.recipe . Singularity runner under the hood runs the following command line: cd {build_path}; singularity build --fakeroot {image_path} Singularity.recipe where: - {build_path} is {MLBOX_ROOT}/build root directory. - {image_path} is the path to Singularity image that is computed as described above.","title":"Build command"},{"location":"runners/singularity-runner/#run-command","text":"Singularity runner runs the following command: singularity run {volumes} {image_path} {args} where: - {volumes} are the mount points that MLBox library automatically constructed based upon task input/output specifications. - {image_path} is the path to Singularity image that is computed as described above. - {args} is the task command line arguments, constructed automatically by the MLBox library.","title":"Run command"},{"location":"runners/ssh-runner/","text":"SSH Runner \u00b6 SSH runner uses other runners to run MLBoxes on remote hosts. It uses ssh and rsync internally. It supports two mandatory commands - configure and run with standard arguments - mlbox , platform and task . SSH platform configuration is used to configure SSH runner. This runner is being actively developed and not features described on this page may be supported. Platform Configuration File \u00b6 SSH platform configuration file is a YAML file. The configuration file for the reference MNIST MLBox is the following: host : REMOTE_HOST # Remote host IP address. user : USER # User name, assuming passwordless authentication using keys has been set up. platform : docker.yaml # How to run MLBox env : # This is for syncing MLBox library itself (library, runners etc.) path : ./mlbox # Path on a remote node, this is the default value. Relative paths are relative to use home dir. sync : true interpreter : # Environment for running runners, mlbox can have its own interpreter. Dependencies must be inst. type : system python : python3.6 # Can also be an absolute path to user python environment (virtualenv, conda etc.) variables : {} # Environmental variables (will be used by docker build/run), remove '{}' if variables present. # http_proxy: # https_proxy: mlbox : # Remote location of the MLBox to run path : # Null, the path will be set to ./.mlbox/mlboxes/mnist-${version} sync : true SSH runner uses IP or name of a remote host ( host ) and ssh tool to login and execute shell commands on remote hosts. It uses user name ( user ) for authentication. If passwordless login is not configured, SSH runner asks for password many times during configure and run phases. SSH runner depends on other runners to run MLBoxes. The platform field specifies what runner should be used on a remote host. This is a file name relative to {MLBOX_ROOT}/platforms . In current implementation, SSH runner synchronizes both MLBox library and MLBox workload between local and remote hosts. This is optional. Build command \u00b6 During the build phase, the following steps are performed. 1. If MLBox library (source tree) needs to be synchronized, SSH runner: - Uses ssh to create root directory for the MLBox library. - Uses rsync to synchronize the following MLBox directories: mlcommons_box and runners . 2. If MLBox workload needs to be synchronized, SSH runner: - Uses ssh to create root directory for the MLBox workload. - Uses rsync to synchronize the entire content of the MLBox workload. 3. The only supported remote python environment is the system , and SSH runner assumes that all dependencies have been installed. Two required python packages that are not common are typer and mlspeclib . 4. SSH runner uses platform file and runs standard configure command on a remote host. Only reference Docker and Singularity runners are supported now. Run command \u00b6 During the run phase, the SSH runner performs the following steps: 1. It uses ssh to run standard run command on a remote host. 2. It uses rsync to synchronize back the content of the {MLBOX_ROOT}/workspace directory.","title":"SSH Runner"},{"location":"runners/ssh-runner/#ssh-runner","text":"SSH runner uses other runners to run MLBoxes on remote hosts. It uses ssh and rsync internally. It supports two mandatory commands - configure and run with standard arguments - mlbox , platform and task . SSH platform configuration is used to configure SSH runner. This runner is being actively developed and not features described on this page may be supported.","title":"SSH Runner"},{"location":"runners/ssh-runner/#platform-configuration-file","text":"SSH platform configuration file is a YAML file. The configuration file for the reference MNIST MLBox is the following: host : REMOTE_HOST # Remote host IP address. user : USER # User name, assuming passwordless authentication using keys has been set up. platform : docker.yaml # How to run MLBox env : # This is for syncing MLBox library itself (library, runners etc.) path : ./mlbox # Path on a remote node, this is the default value. Relative paths are relative to use home dir. sync : true interpreter : # Environment for running runners, mlbox can have its own interpreter. Dependencies must be inst. type : system python : python3.6 # Can also be an absolute path to user python environment (virtualenv, conda etc.) variables : {} # Environmental variables (will be used by docker build/run), remove '{}' if variables present. # http_proxy: # https_proxy: mlbox : # Remote location of the MLBox to run path : # Null, the path will be set to ./.mlbox/mlboxes/mnist-${version} sync : true SSH runner uses IP or name of a remote host ( host ) and ssh tool to login and execute shell commands on remote hosts. It uses user name ( user ) for authentication. If passwordless login is not configured, SSH runner asks for password many times during configure and run phases. SSH runner depends on other runners to run MLBoxes. The platform field specifies what runner should be used on a remote host. This is a file name relative to {MLBOX_ROOT}/platforms . In current implementation, SSH runner synchronizes both MLBox library and MLBox workload between local and remote hosts. This is optional.","title":"Platform Configuration File"},{"location":"runners/ssh-runner/#build-command","text":"During the build phase, the following steps are performed. 1. If MLBox library (source tree) needs to be synchronized, SSH runner: - Uses ssh to create root directory for the MLBox library. - Uses rsync to synchronize the following MLBox directories: mlcommons_box and runners . 2. If MLBox workload needs to be synchronized, SSH runner: - Uses ssh to create root directory for the MLBox workload. - Uses rsync to synchronize the entire content of the MLBox workload. 3. The only supported remote python environment is the system , and SSH runner assumes that all dependencies have been installed. Two required python packages that are not common are typer and mlspeclib . 4. SSH runner uses platform file and runs standard configure command on a remote host. Only reference Docker and Singularity runners are supported now.","title":"Build command"},{"location":"runners/ssh-runner/#run-command","text":"During the run phase, the SSH runner performs the following steps: 1. It uses ssh to run standard run command on a remote host. 2. It uses rsync to synchronize back the content of the {MLBOX_ROOT}/workspace directory.","title":"Run command"}]}